---
output:
  html_document:
    highlight: haddock
    theme: cerulean
---

![](logo.jpg)

Curso: Métodos Avanzados en Minería de Datos
=========================================

Métodos de Predictivos (Clasificación o Aprendizaje-Supervisado)
========================================================

Dr. Oldemar Rodríguez
--------------------------

Índices de Calidad del Modelo 
===================================

```{r st1,comment=NA}
# Índices para matrices NxN
indices.general <- function(MC) {
  precision.global <- sum(diag(MC))/sum(MC)
  error.global <- 1 - precision.global
  precision.categoria <- diag(MC)/rowSums(MC)
  res <- list(matriz.confusion = MC, precision.global = precision.global, error.global = error.global, 
              precision.categoria = precision.categoria)
  names(res) <- c("Matriz de Confusión", "Precisión Global", "Error Global", 
                  "Precisión por categoría")
  return(res)
}
```

El método de los K vecinos más cercanos
===================================

Ejemplo Scoring
----------------

```{r comment=NA}
library(kknn)
setwd("~/Google Drive/MDCurso/Datos")
taprendizaje<-read.csv("MuestraAprendizajeCredito2500.csv",sep = ";",header=T)
dim(taprendizaje)
# Recodifica las variables como cualitativas
taprendizaje$MontoCredito <- as.factor(taprendizaje$MontoCredito)
taprendizaje$IngresoNeto <- as.factor(taprendizaje$IngresoNeto)
taprendizaje$CoefCreditoAvaluo <- as.factor(taprendizaje$CoefCreditoAvaluo)
taprendizaje$MontoCuota <- as.factor(taprendizaje$MontoCuota)
taprendizaje$GradoAcademico <- as.factor(taprendizaje$GradoAcademico)
## Usamos una nueva tabla de testing para validar
ttesting<-read.csv("MuestraTestCredito2500.csv",sep = ";",header=T)
# Convirtiendo las variables tipo Factor
ttesting$MontoCredito <- as.factor(ttesting$MontoCredito)
ttesting$IngresoNeto <- as.factor(ttesting$IngresoNeto)
ttesting$CoefCreditoAvaluo <- as.factor(ttesting$CoefCreditoAvaluo)
ttesting$MontoCuota <- as.factor(ttesting$MontoCuota)
ttesting$GradoAcademico <- as.factor(ttesting$GradoAcademico)
modelo <- train.kknn(BuenPagador~.,data=taprendizaje,kmax=7)
modelo
prediccion<-predict(modelo,ttesting[,-6])
## Matriz de Confusión
MC<-table(ttesting[,6],prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Ejemplo Iris
----------------

```{r comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
suppressWarnings(suppressMessages(library(kknn)))
## Vamos a generar al azar una tabla de testing de tamaño 50 y una tabla de aprendizaje de tamaño 100.
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
# train.kknn escoje el k usando leave-one-out crossvalidation
modelo<-train.kknn(tipo~.,data=taprendizaje,kmax=9)
modelo
prediccion<-predict(modelo,ttesting[,-5])
prediccion
## Matriz de Confusión
MC<-table(ttesting[,5],prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Método de Bayes
========================================================

Ejemplo Iris
-------------

```{r eje3,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
library(e1071)
datos <- read.csv("iris.csv",sep = ";",dec='.',header=TRUE)
head(datos)
summary(datos)
```

## Vamos a generar al azar una tabla de testing de tamaño 50 y una tabla de aprendizaje de tamaño 100.

```{r eje4,comment=NA}
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
modelo <- naiveBayes(tipo~.,data=taprendizaje)
```

## Prediccion, Matriz de Confusión e Índices de Calidad

```{r eje5,comment=NA}
prediccion <- predict(modelo, ttesting[,-5])
MC <- table(ttesting[,5],prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Ejemplo Credit Scoring
-------------------------
## Aprende con taprendizaje[,1:5] y con la variable a predecir taprendizaje[,6]

```{r eje7,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
taprendizaje<-read.csv("MuestraAprendizajeCredito2500.csv",sep = ";",header=TRUE)
# Recodifica las variables como cualitativas
taprendizaje$MontoCredito <- as.factor(taprendizaje$MontoCredito)
taprendizaje$IngresoNeto <- as.factor(taprendizaje$IngresoNeto)
taprendizaje$CoefCreditoAvaluo <- as.factor(taprendizaje$CoefCreditoAvaluo)
taprendizaje$MontoCuota <- as.factor(taprendizaje$MontoCuota)
taprendizaje$GradoAcademico <- as.factor(taprendizaje$GradoAcademico)
modelo<-naiveBayes(BuenPagador~.,data=taprendizaje)
```

## Usando una nueva tabla de testing para validar y calculando la Matriz de Confusión

```{r eje8,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
ttesting<-read.csv("MuestraTestCredito2500.csv",sep = ";",header=TRUE)
# Convirtiendo las variables tipo Factor
ttesting$MontoCredito <- as.factor(ttesting$MontoCredito)
ttesting$IngresoNeto <- as.factor(ttesting$IngresoNeto)
ttesting$CoefCreditoAvaluo <- as.factor(ttesting$CoefCreditoAvaluo)
ttesting$MontoCuota <- as.factor(ttesting$MontoCuota)
ttesting$GradoAcademico <- as.factor(ttesting$GradoAcademico)
prediccion<-predict(modelo, ttesting[,1:5])
MC<-table(ttesting[,6],prediccion)
```

# Porcentaje de clasificación

```{r eje9,comment=NA}
# Índices de Calidad de la predicción
indices.general(MC)
```

Máquinas de Soporte Vectorial
==============================

Ejemplo Iris
-------------

```{r svm1,comment=NA}
setwd("~/Google Drive/MDCurso/Datos") 
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
head(datos)
summary(datos)
library(class)
library(e1071)
```

#### Vamos a generar al azar una tabla de testing de tamaño 50 y una tabla de aprendizaje de tamaño 100.

```{r svm2,comment=NA}
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
modelo <- svm(tipo~., data = taprendizaje, kernel = "linear")
modelo
# Prediccion y Matriz de Confusion
prediccion <- predict(modelo,ttesting)
prediccion
MC<-table(ttesting[,5],prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Usando solo 2 variables para poder graficar
-------------------------------------------

```{r svm3,comment=NA}
modelo <- svm(tipo ~ s.largo + s.ancho, data = taprendizaje, kernel = "linear")
plot(modelo,datos,s.ancho~s.largo, slice = list(s.ancho=1,s.largo=2))
```

Kernel no Lineal 
----------------

```{r svm4,comment=NA}
modelo <- svm(tipo~., data = taprendizaje)
modelo
# Prediccion y Matriz de Confusion
prediccion <- predict(modelo,ttesting)
MC<-table(ttesting[,5],prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```


Usando solo 2 variables para poder graficar
---------------------------------------------

```{r svm5,comment=NA}
modelo <- svm(tipo ~ s.largo + s.ancho, data = taprendizaje)
modelo
plot(modelo,datos,s.ancho~s.largo, slice = list(s.ancho=1,s.largo=2))
```

Ejemplo Credit Scoring
----------------------

```{r svm6,comment=NA}
setwd("~/Google Drive/MDCurso/Datos") 
taprendizaje<-read.csv("MuestraAprendizajeCredito2500.csv",sep = ";",header=T)
# Recodifica las variables como cualitativas
taprendizaje$MontoCredito <- as.factor(taprendizaje$MontoCredito)
taprendizaje$IngresoNeto <- as.factor(taprendizaje$IngresoNeto)
taprendizaje$CoefCreditoAvaluo <- as.factor(taprendizaje$CoefCreditoAvaluo)
taprendizaje$MontoCuota <- as.factor(taprendizaje$MontoCuota)
taprendizaje$GradoAcademico <- as.factor(taprendizaje$GradoAcademico)
## Usamos una nueva tabla de testing para validar
ttesting<-read.csv("MuestraTestCredito2500.csv",sep = ";",header=T)
# Convirtiendo las variables tipo Factor
ttesting$MontoCredito <- as.factor(ttesting$MontoCredito)
ttesting$IngresoNeto <- as.factor(ttesting$IngresoNeto)
ttesting$CoefCreditoAvaluo <- as.factor(ttesting$CoefCreditoAvaluo)
ttesting$MontoCuota <- as.factor(ttesting$MontoCuota)
ttesting$GradoAcademico <- as.factor(ttesting$GradoAcademico)
modelo <- svm(BuenPagador~., data=taprendizaje)
modelo
## Prediccion y Matriz de Confusión
prediccion <- predict(modelo,ttesting)
MC<-table(ttesting[,6],prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Árboles de Decisión
=====================

Usando el paquete rpart y rpart.plot
===================================

El paquete "rpart" utiliza el algoritmo CART + Pruning (poda)
--------------------------------------------------------------

Ejemplo Iris
------------

## Vamos a generar al azar una tabla de testing de tamaño 50 
## y una tabla de aprendizaje de tamaño 100.

```{r arb3,comment=NA}
library(rpart)
library(rpart.plot)
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
modelo <- rpart(tipo~.,data=taprendizaje)
# Type="class" hace que el modelo prediga clases y no valores de Regresión
# pues lo árboles pueden ser usados para regresión
prediccion <- predict(modelo, ttesting, type='class')
prp(modelo,extra=104,branch.type=2, box.col=c("pink", "palegreen3","cyan")[modelo$frame$yval])
```

## Matriz de Confusión

```{r arb4,comment=NA}
MC<-table(ttesting$tipo,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

## Generar el árbol cambiando la cantidad mínima de individuos en los nodos hoja (terminales). 

## Es decir, modificando el parámetro "minsplit = 20"


```{r arb31,comment=NA}
library(rpart)
library(rpart.plot)
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
# Un individuos máximo en los nodos terminales
modelo <- rpart(tipo~.,data=taprendizaje,minsplit=1)
# Type="class" hace que el modelo prediga clases y no valores de Regresión
# pues lo árboles pueden ser usados para regresión
prediccion <- predict(modelo, ttesting, type='class')
prp(modelo,extra=104,branch.type=2, box.col=c("pink", "palegreen3","cyan")[modelo$frame$yval])
```

## Matriz de Confusión

```{r arb41,comment=NA}
MC<-table(ttesting$tipo,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

## Generando el Árbol con menos variables predictoras

```{r arb5,comment=NA}
modelo <- rpart(tipo~p.largo+p.ancho,data=taprendizaje)
modelo
prp(modelo,extra=104,branch.type=2, box.col=c("pink", "palegreen3","cyan")[modelo$frame$yval])
```


Ejemplo Scoring con rpart
--------------------------

```{r arb6,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
taprendizaje<-read.csv("MuestraAprendizajeCredito2500.csv",sep = ";",header=T)
# Recodifica las variables como cualitativas
taprendizaje$MontoCredito <- as.factor(taprendizaje$MontoCredito)
taprendizaje$IngresoNeto <- as.factor(taprendizaje$IngresoNeto)
taprendizaje$CoefCreditoAvaluo <- as.factor(taprendizaje$CoefCreditoAvaluo)
taprendizaje$MontoCuota <- as.factor(taprendizaje$MontoCuota)
taprendizaje$GradoAcademico <- as.factor(taprendizaje$GradoAcademico)
summary(taprendizaje)
modelo1 = rpart(BuenPagador~.,data=taprendizaje)
plot(modelo1)
text(modelo1)
prp(modelo1,extra=104,branch.type=2, box.col=c("pink", "palegreen3")[modelo1$frame$yval])
```

## Usamos una nueva tabla de testing para validar
```{r arb7,comment=NA}
setwd("~/Google Drive/MDCurso/Datos") 
ttesting<-read.csv("MuestraTestCredito2500.csv",sep = ";",header=T)
# Convirtiendo las variables tipo Factor
ttesting$MontoCredito <- as.factor(ttesting$MontoCredito)
ttesting$IngresoNeto <- as.factor(ttesting$IngresoNeto)
ttesting$CoefCreditoAvaluo <- as.factor(ttesting$CoefCreditoAvaluo)
ttesting$MontoCuota <- as.factor(ttesting$MontoCuota)
ttesting$GradoAcademico <- as.factor(ttesting$GradoAcademico)
summary(ttesting)
prediccion <- predict(modelo1, ttesting, type='class')
```

## Matriz de Confusión

```{r arb8,comment=NA}
MC<-table(ttesting$BuenPagador,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Bosques Aleatorios (Random Forest)
==================================

Ejemplo Iris
------------

```{r ba1,comment=NA}
library(randomForest)
# Leyendo Datos
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
```

#### Vamos a generar al azar una tabla de testing de tamaño 50 y una tabla de aprendizaje de tamaño 100.

```{r ba2,comment=NA}
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
modelo<-randomForest(tipo~.,data=taprendizaje,importance=TRUE)
modelo
varImpPlot(modelo)
prediccion<-predict(modelo, ttesting[,-5])
prediccion
## Matriz de Confusión
MC<-table(ttesting$tipo,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Ejemplo Scoring
------------------

```{r ba3,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
taprendizaje<-read.csv("MuestraAprendizajeCredito2500.csv",sep = ";",header=T)
# Recodifica las variables como cualitativas
taprendizaje$MontoCredito <- as.factor(taprendizaje$MontoCredito)
taprendizaje$IngresoNeto <- as.factor(taprendizaje$IngresoNeto)
taprendizaje$CoefCreditoAvaluo <- as.factor(taprendizaje$CoefCreditoAvaluo)
taprendizaje$MontoCuota <- as.factor(taprendizaje$MontoCuota)
taprendizaje$GradoAcademico <- as.factor(taprendizaje$GradoAcademico)
modelo<-randomForest(BuenPagador~.,data=taprendizaje,importance=TRUE)
modelo
varImpPlot(modelo)
## Usamos una nueva tabla de testing para validar
ttesting<-read.csv("MuestraTestCredito2500.csv",sep = ";",header=T)
# Convirtiendo las variables tipo Factor
ttesting$MontoCredito <- as.factor(ttesting$MontoCredito)
ttesting$IngresoNeto <- as.factor(ttesting$IngresoNeto)
ttesting$CoefCreditoAvaluo <- as.factor(ttesting$CoefCreditoAvaluo)
ttesting$MontoCuota <- as.factor(ttesting$MontoCuota)
ttesting$GradoAcademico <- as.factor(ttesting$GradoAcademico)
prediccion<-predict(modelo, ttesting[,-6])
## Matriz de Confusión
MC<-table(ttesting$BuenPagador,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Métodos de Potenciación - ADA - Boosting (solo para 2 clases)
==================================

Ejemplo Scoring
---------------

```{r boos1,comment=NA}
library(ada)
# Leyendo Datos
setwd("~/Google Drive/MDCurso/Datos")
taprendizaje<-read.csv("MuestraAprendizajeCredito2500.csv",sep = ";",header=T)
# Recodifica las variables como cualitativas
taprendizaje$MontoCredito <- as.factor(taprendizaje$MontoCredito)
taprendizaje$IngresoNeto <- as.factor(taprendizaje$IngresoNeto)
taprendizaje$CoefCreditoAvaluo <- as.factor(taprendizaje$CoefCreditoAvaluo)
taprendizaje$MontoCuota <- as.factor(taprendizaje$MontoCuota)
taprendizaje$GradoAcademico <- as.factor(taprendizaje$GradoAcademico)
modelo<-ada(BuenPagador~.,data=taprendizaje,iter=20,nu=1,type="discrete")
modelo
# Graficar el modelo
plot(modelo,TRUE,TRUE)
# Importancia de la variables
varplot(modelo)
## Usamos una nueva tabla de testing para validar
ttesting<-read.csv("MuestraTestCredito2500.csv",sep = ";",header=T)
# Convirtiendo las variables tipo Factor
ttesting$MontoCredito <- as.factor(ttesting$MontoCredito)
ttesting$IngresoNeto <- as.factor(ttesting$IngresoNeto)
ttesting$CoefCreditoAvaluo <- as.factor(ttesting$CoefCreditoAvaluo)
ttesting$MontoCuota <- as.factor(ttesting$MontoCuota)
ttesting$GradoAcademico <- as.factor(ttesting$GradoAcademico)
prediccion<-predict(modelo, ttesting[,-6])
## Matriz de Confusión
MC<-table(ttesting$BuenPagador,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

## Métodos de Potenciación - eXtreme Gradient Boosting - para 2 clases

### Ejemplo Scoring

```{r boos12,comment=NA}
library(xgboost)
# Leyendo Datos
setwd("~/Google Drive/MDCurso/Datos")
taprendizaje<-read.csv("MuestraAprendizajeCredito2500.csv",sep = ";",header=T)
# Recodifica las variables como cualitativas
taprendizaje$MontoCredito <- as.factor(taprendizaje$MontoCredito)
taprendizaje$IngresoNeto <- as.factor(taprendizaje$IngresoNeto)
taprendizaje$CoefCreditoAvaluo <- as.factor(taprendizaje$CoefCreditoAvaluo)
taprendizaje$MontoCuota <- as.factor(taprendizaje$MontoCuota)
taprendizaje$GradoAcademico <- as.factor(taprendizaje$GradoAcademico)
taprendizaje$BuenPagador <- as.numeric(ifelse(taprendizaje$BuenPagador == "Si", "1", "0"))
str(taprendizaje)
## Usamos una nueva tabla de testing para validar
ttesting<-read.csv("MuestraTestCredito2500.csv",sep = ";",header=T)
# Recodifica las variables como cualitativas
taprendizaje$MontoCredito <- as.factor(taprendizaje$MontoCredito)
taprendizaje$IngresoNeto <- as.factor(taprendizaje$IngresoNeto)
taprendizaje$CoefCreditoAvaluo <- as.factor(taprendizaje$CoefCreditoAvaluo)
taprendizaje$MontoCuota <- as.factor(taprendizaje$MontoCuota)
taprendizaje$GradoAcademico <- as.factor(taprendizaje$GradoAcademico)
ttesting$BuenPagador <- as.numeric(ifelse(ttesting$BuenPagador == "Si", "1", "0"))

# Guarda la variable a predecir
valor.variable.predecir <- ttesting$BuenPagador

# Convierte a int de num
taprendizaje[] <- lapply(taprendizaje, as.numeric)
ttesting[] <- lapply(ttesting, as.numeric)

# Las adapta al paquete xgboost 
taprendizaje <- xgb.DMatrix(data = data.matrix(taprendizaje[,-6]),label = data.matrix(taprendizaje$BuenPagador))
ttesting <- xgb.DMatrix(data = data.matrix(ttesting[,-6]),label = data.matrix(ttesting$BuenPagador))

# Parámetros del modelo
parametros <- list(booster = "gbtree", objective = "binary:logistic", eta=0.3, 
               gamma=0, max_depth=6, min_child_weight=1, subsample=1, colsample_bytree=1)
modelo <- xgb.train (params = parametros, data = taprendizaje, nrounds = 79, 
                  watchlist = list(train=taprendizaje, test=ttesting), print_every_n = 10, 
                  early_stop_round = 10, maximize = F , eval_metric = "error")

prediccion <- predict (modelo, ttesting)
head(prediccion)
prediccion <- ifelse (prediccion > 0.5, 1, 0)
MC <- table(prediccion, valor.variable.predecir)
MC
# Índices de Calidad de la predicción
indices.general(MC)

#Importancia de las Variables
variables.importantes <- xgb.importance(feature_names = colnames(taprendizaje), model = modelo)
xgb.plot.importance(importance_matrix = variables.importantes)
```

## Métodos de Potenciación - eXtreme Gradient Boosting - para más de 2 clases

### Ejemplo Iris

```{r boos13,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
taprendizaje$tipo <- as.numeric(taprendizaje$tipo)-1
ttesting$tipo <- as.numeric(ttesting$tipo)-1
valor.variable.predecir <- ttesting$tipo

taprendizaje <- xgb.DMatrix(data = data.matrix(taprendizaje[,-5]),label = data.matrix(taprendizaje$tipo))
ttesting <- xgb.DMatrix(data = data.matrix(ttesting[,-5]),label = data.matrix(ttesting$tipo))

# Parámetros del modelo
# OJO objective = "multi:softprob"
parametros <- list(booster = "gbtree", objective = "multi:softprob", eta=0.3, 
                   gamma=0, max_depth=6, min_child_weight=1, subsample=1, colsample_bytree=1,num_class = 3)

# OJO eval_metric = "mlogloss"
modelo <- xgb.train(params = parametros, data = taprendizaje, nrounds = 79, 
                     watchlist = list(train=taprendizaje, test=ttesting), print_every_n = 10, 
                     early_stop_round = 10, maximize = F , eval_metric = "mlogloss")

prediccion <- predict(modelo, ttesting)
head(prediccion)
# Convierte la probabilidad en una matriz con tres probabilidades
prediccion <- matrix(prediccion, ncol=3, byrow=TRUE)
head(prediccion)
# Convierte las probabilidades a etiquetas de clase
pred_clase <- max.col(prediccion) - 1
head(pred_clase)

MC <- table(pred_clase, valor.variable.predecir)
MC
# Índices de Calidad de la predicción
indices.general(MC)

#Importancia de las Variables
variables.importantes <- xgb.importance(feature_names = colnames(taprendizaje), model = modelo)
xgb.plot.importance(importance_matrix = variables.importantes)
```

Redes Neuronales
==================================

Ejemplo Iris
------------

```{r rn1,comment=NA}
library(nnet)
# Leyendo Datos
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
```

#### Vamos a generar al azar una tabla de testing de tamaño 50 y una tabla de aprendizaje de tamaño 100.

```{r rn2,comment=NA}
library(nnet)
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
# size = número de capas ocultas
# rang = pesos iniciales
# decay = grado de decrecimiento de los pesos
# maxit = número máximo de iteraciones (default=100)
# MaxNWts = Número máximo de pesos (default=1000)
modelo<-nnet(tipo~.,data=taprendizaje,size = 4, rang = 0.1,decay = 5e-4, maxit = 200,trace=FALSE)
modelo
# Type="class" hace que el modelo prediga clases y no valores de Regresión
prediccion<-predict(modelo, ttesting[,-5],type = "class")
prediccion
## Matriz de Confusión
MC<-table(ttesting$tipo,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Ejemplo Scoring
------------------

```{r rn3,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
taprendizaje<-read.csv("MuestraAprendizajeCredito2500.csv",sep = ";",header=T)
# Importante size=250, con size=2 la predicción será muy mala
modelo<-nnet(BuenPagador~.,data=taprendizaje,size = 250,MaxNWts=2000,rang = 0.1,decay = 5e-4, maxit = 400,trace=FALSE)
modelo
## Usamos una nueva tabla de testing para validar
ttesting<-read.csv("MuestraTestCredito2500.csv",sep = ";",header=T)
prediccion<-predict(modelo, ttesting[,-6],type = "class")
## Matriz de Confusión
MC<-table(ttesting$BuenPagador,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Guardando un Modelo para su posterior uso
=========================================

Ejemplo con Redes Neuronales e Iris
------------------------------------

Guardar en disco el modelo
-------------------------

```{r guarda1,comment=NA}
library(nnet)
# Leyendo Datos
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
muestra <- sample(1:150,50)
taprendizaje <- datos[-muestra,]
modelo<-nnet(tipo~.,data=taprendizaje,size = 4, rang = 0.1,decay = 5e-4, maxit = 200,trace=FALSE)
#Guarda el modelo
save(modelo, file = "modelo_redes_iris.rda")
```


Un mes después, por ejemplo, lee el modelo y hace predicciones
-----------------------------------------

```{r guarda2,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
# Automáticamente queda en la variable en la que fue guardada, o sea modelo
load("modelo_redes_iris.rda")  
# Type="class" hace que el modelo prediga clases y no valores de Regresión
prediccion<-predict(modelo, ttesting[,-5],type = "class")
## Matriz de Confusión
MC<-table(ttesting$tipo,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

Ejemplo con los datos de Scoring y Bosques Aleatorios
-----------------------------------------------------

Guardar en disco el modelo
-------------------------

```{r guarda3,comment=NA}
# Leyendo Datos
setwd("~/Google Drive/MDCurso/Datos")
taprendizaje<-read.csv("MuestraAprendizajeCredito2500.csv",sep = ";",header=T)
modelo<-randomForest(BuenPagador~.,data=taprendizaje,importance=TRUE)
#Guarda el modelo
save(modelo, file = "modelo_bosques_scoring.rda")
```


Un mes después, por ejemplo, lee el modelo y hacen predicciones
-----------------------------------------

```{r guarda4,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
ttesting<-read.csv("MuestraTestCredito2500.csv",sep = ";",header=T)
# Lee el modelo del disco duro
load("modelo_bosques_scoring.rda")  
prediccion<-predict(modelo, ttesting[,-6])
## Matriz de Confusión
MC<-table(ttesting$BuenPagador,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```



---
output:
  html_document: 
    df_print: paged
    highlight: haddock
    theme: cerulean
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = NA, fig.width = 15, fig.height = 10)
```

![](logo.jpg)

---

# Calibración y Selección de Modelos

La calibración de un modelo consiste en la selección de los mejores parámetros del modelo según un problema determinado.

**Calibrando el método "Máquinas Vectoriales de Soporte" para los datos de Scoring de Crédito**

## Versión NO Paralela

**En el caso del Scoring de Crédito lo que más interesa en detectar a los NO pagadores, por esa razón ejecutaremos 5 veces la validación cruzada usando 10 grupos. En cada paso de la valización cruzada vamos sumando los no pagadores detectados, luego para cada ejecución de la valizadación cruzada almacenamos la detección de los no pagadores en una entrada del vector respectivo al método para luego hacer un gráfico comparativo. Para esto usaremos archivo "MuestraCredito5000V2.csv""**


**Cargamos los datos**
```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

## {.tabset}

### Paquete e1071

**Cargamos las librerías**
```{r}
library(caret)
library(e1071)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.radial <- c()
deteccion.no.linear <- c()
deteccion.no.polynomial <- c()
deteccion.no.sigmoid <- c()

tiempo.usual <- Sys.time() 

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  deteccion.no.radial[i] <- no.radial
  deteccion.no.linear[i] <- no.linear
  deteccion.no.polynomial[i] <- no.polynomial
  deteccion.no.sigmoid[i] <- no.sigmoid
}

tiempo.usual <- Sys.time() -  tiempo.usual
```

**El tiempo que tarda en ejecutarse.**
```{r}
tiempo.usual
```
**Nota**: El tiempo que tarda en terminar el proceso puede variar de computadora a computadora y de ejecución en ejecución.

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
resultados <- data.frame("radial" = deteccion.no.radial,
                         "linear" = deteccion.no.linear,
                         "polynomial" = deteccion.no.polynomial,
                         "sigmoid" = deteccion.no.sigmoid) #Preparamos los datos

par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

### Paquete trainR

**Se cargan las librerías**
```{r}
library(caret)
library(trainR)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.radial <- c()
deteccion.no.linear <- c()
deteccion.no.polynomial <- c()
deteccion.no.sigmoid <- c()

tiempo.usual <- Sys.time()

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  deteccion.no.radial[i] <- no.radial
  deteccion.no.linear[i] <- no.linear
  deteccion.no.polynomial[i] <- no.polynomial
  deteccion.no.sigmoid[i] <- no.sigmoid
}

tiempo.usual <- Sys.time() - tiempo.usual
```

**El tiempo que tarda en ejecutarse.**
```{r}
tiempo.usual
```
**Nota**: El tiempo que tarda en terminar el proceso puede variar de computadora a computadora y de ejecución en ejecución.

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
resultados <- data.frame("radial" = deteccion.no.radial,
                         "linear" = deteccion.no.linear,
                         "polynomial" = deteccion.no.polynomial,
                         "sigmoid" = deteccion.no.sigmoid) #Preparamos los datos

par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

**Otra forma de hacerlo es:**

**Se cargan las librerías**
```{r}
library(caret)
library(trainR)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10
kernels <- c("radial", "linear", "polynomial", "sigmoid")

resultados <- matrix(0, nrow = cantidad.validacion.cruzada, ncol = 4) # ncol la cantidad de modelos a usar
colnames(resultados) <- kernels # opcional

tiempo.usual <- Sys.time()

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    for(kernel in kernels) {
      modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = kernel, probability = FALSE)
      prediccion <- predict(modelo, ttesting)
      MC <- confusion.matrix(ttesting, prediccion)
      resultados[i, kernel] <- resultados[i, kernel] + MC["No","No"] # Detección de los NO Pagadores
    }
  }
}

tiempo.usual <- Sys.time() - tiempo.usual

```

**El tiempo que tarda en ejecutarse.**
```{r}
tiempo.usual
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

##

## Versión Paralela

Hacer este proceso puede tardar demasiado, por lo que podemos paralelizar para disminuir el tiempo de cálculo.

## {.tabset}

### Paquete e1071

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(e1071)
  library(caret)
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  return(data.frame("radial"     = no.radial, 
                    "linear"     = no.linear, 
                    "polynomial" = no.polynomial, 
                    "sigmoid"    = no.sigmoid))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp) # No olvidar cerrar el proceso
```

**El tiempo que tarda en ejecutarse.**
```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados) # Unimos cada lista
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

### Paquete trainR

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(trainR)
  library(caret)
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  return(list("radial"     = no.radial, 
              "linear"     = no.linear, 
              "polynomial" = no.polynomial, 
              "sigmoid"    = no.sigmoid))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

**El tiempo que tarda en ejecutarse.**
```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

**Otra forma de hacerlo es:**

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5
clusterExport(clp, "cantidad.validacion.cruzada")

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(trainR)
  library(caret)
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  kernels <- c("radial", "linear", "polynomial", "sigmoid")
  
  # nrow = 1 porque cada proceso es una validacion por aparte
  resultados <- matrix(0, nrow = 1, ncol = 4) # ncol la cantidad de modelos a usar
  colnames(resultados) <- kernels # opcional

  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    for(kernel in kernels) {
      modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = kernel, probability = FALSE)
      prediccion <- predict(modelo, ttesting)
      MC <- confusion.matrix(ttesting, prediccion)
      resultados[1, kernel] <- resultados[1, kernel] + MC["No","No"] # Detección de los NO Pagadores
    }
  }
  return(resultados)
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

**El tiempo que tarda en ejecutarse.**
```{r}
tiempo.paralelo
```

**El resultado es una lista de matrices, debemos de convertirlo para manejarlo mejor**

```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

##

---

# Seleccionando el mejor método para los datos de Scoring de Crédito

## Versión NO Paralela

## {.tabset}

### Paquetes

**Se cargan las librerías**
```{r}
library(caret)
library(e1071)
library(kknn)
library(class)
library(rpart)
library(randomForest)
library(ada)
library(nnet)
library(magrittr)
library(dplyr)
```

```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

```{r results="hide"}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.svm <- c()
deteccion.no.knn <- c()
deteccion.no.bayes <- c()
deteccion.no.arbol <- c()
deteccion.no.bosque <- c()
deteccion.no.potenciacion <- c()
deteccion.no.red <- c()

# Medimos tiempo de ejecución
tiempo.no.paralelo <- Sys.time()

# Validación cruzada 5 veces
for (i in 1:cantidad.validacion.cruzada) {
  grupos <- createFolds(1:numero.filas, cantidad.grupos) # Crea los 10 grupos
  no.svm <- 0
  no.knn <- 0
  no.bayes <- 0
  no.arbol <- 0
  no.bosque <- 0
  no.potenciacion <- 0
  no.red <- 0
  
  # Este ciclo es el que hace validación cruzada con 10 grupos
  for (k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- svm(BuenPagador ~ ., data = ttraining, kernel = "linear")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.svm <- no.svm + MC["No", "No"]
    
    modelo <- train.kknn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.knn <- no.knn + MC["No", "No"]
    
    modelo <- naiveBayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.bayes <- no.bayes + MC["No", "No"]
    
    modelo = rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting, type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.arbol <- no.arbol + MC["No", "No"]
    
    modelo <- randomForest(BuenPagador ~ ., data = ttraining, importance = TRUE)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.bosque <- no.bosque + MC["No", "No"]
    
    modelo <- ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.potenciacion <- no.potenciacion + MC["No", "No"]
    
    modelo <- nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
                   decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting[, -6], type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, factor(prediccion, levels = levels(Actual)), exclude = FALSE)
    # Detección de los No Pagadores
    no.red <- no.red + MC["No", "No"]
  }
  deteccion.no.svm[i] <- no.svm
  deteccion.no.knn[i] <- no.knn
  deteccion.no.bayes[i] <- no.bayes
  deteccion.no.arbol[i] <- no.arbol
  deteccion.no.bosque[i] <- no.bosque
  deteccion.no.potenciacion[i] <- no.potenciacion
  deteccion.no.red[i] <- no.red
}

tiempo.no.paralelo <- Sys.time() - tiempo.no.paralelo
```

**Tiempo de ejecución**
```{r}
tiempo.no.paralelo
```

**Graficamos los resultados**
```{r}
resultados <- data.frame("svm" = deteccion.no.svm,
                         "k_vecinos" = deteccion.no.knn,
                         "bayes" = deteccion.no.bayes,
                         "arboles" = deteccion.no.arbol,
                         "bosques" = deteccion.no.bosque,
                         "potenciacion" = deteccion.no.potenciacion,
                         "redes_nnet" = deteccion.no.red)

par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

### Paquete trainR

La manipulación de los datos se puede hacer muy pesada cuando tratamos con `xgboost` y `neuralnet`, pero con `trainR` resulta más fácil.

**Se cargan las librerías**
```{r}
library(caret)
library(trainR)
```

```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

```{r message=FALSE, warning=FALSE , results="hide"}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.svm <- c()
deteccion.no.knn <- c()
deteccion.no.bayes <- c()
deteccion.no.arbol <- c()
deteccion.no.bosque <- c()
deteccion.no.potenciacion <- c()
deteccion.no.red <- c()
deteccion.no.xgboost <- c()
deteccion.no.red.neu <- c()
deteccion.no.glm <- c()

# Medimos tiempo de ejecución
tiempo.no.paralelo <- Sys.time()

# Validación cruzada 5 veces
for (i in 1:cantidad.validacion.cruzada) {
  grupos <- createFolds(1:numero.filas, cantidad.grupos) # Crea los 10 grupos
  no.svm <- 0
  no.knn <- 0
  no.bayes <- 0
  no.arbol <- 0
  no.bosque <- 0
  no.potenciacion <- 0
  no.red <- 0
  no.xg  <- 0
  no.red.neu <- 0
  no.glm <- 0
  
  # Este ciclo es el que hace validación cruzada con 10 grupos
  for (k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- train.svm(BuenPagador ~ ., data = ttraining, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.svm <- no.svm + MC["No", "No"]
    
    modelo <- train.knn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.knn <- no.knn + MC["No", "No"]
    
    modelo <- train.bayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.bayes <- no.bayes + MC["No", "No"]
    
    modelo = train.rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.arbol <- no.arbol + MC["No", "No"]
    
    modelo <- train.randomForest(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.bosque <- no.bosque + MC["No", "No"]
    
    modelo <- train.ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.potenciacion <- no.potenciacion + MC["No", "No"]
    
    modelo <- train.nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
               decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.red <- no.red + MC["No", "No"]
    
    modelo <- train.xgboost(BuenPagador ~ ., data = ttraining, nrounds = 79,
                        print_every_n = 10, maximize = F , eval_metric = "error")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.xg <- no.xg + MC["No", "No"]
    
    modelo <- train.neuralnet(BuenPagador ~., data = ttraining, hidden = c(3, 2,6), 
                          linear.output = FALSE, threshold = 0.5, stepmax = 1e+06)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.red.neu <- no.red.neu + MC["No", "No"]
    
    modelo <- train.glm(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.glm <- no.glm + MC["No", "No"]
  }
  deteccion.no.svm[i] <- no.svm
  deteccion.no.knn[i] <- no.knn
  deteccion.no.bayes[i] <- no.bayes
  deteccion.no.arbol[i] <- no.arbol
  deteccion.no.bosque[i] <- no.bosque
  deteccion.no.potenciacion[i] <- no.potenciacion
  deteccion.no.red[i] <- no.red
  deteccion.no.xgboost[i] <- no.xg
  deteccion.no.red.neu[i] <- no.red.neu
  deteccion.no.glm[i] <- no.glm
}

tiempo.no.paralelo <- Sys.time() - tiempo.no.paralelo
```

**Tiempo de ejecución**
```{r}
tiempo.no.paralelo
```

**Graficamos los resultados**
```{r}
resultados <- data.frame("svm" = deteccion.no.svm,
                         "k_vecinos" = deteccion.no.knn,
                         "bayes" = deteccion.no.bayes,
                         "arboles" = deteccion.no.arbol,
                         "bosques" = deteccion.no.bosque,
                         "potenciacion" = deteccion.no.potenciacion,
                         "redes_nnet" = deteccion.no.red,
                         "xgboost" = deteccion.no.xgboost,
                         "redes_neuralnet" = no.red.neu, 
                         "regresion_logistica" = deteccion.no.glm)

par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

**Otra manera de hacerlo:**
```{r message=FALSE, warning=FALSE , results="hide"}
library(trainR)
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

metodos <- c("svm", "k_vecinos", "bayes", "arboles", "bosques", "potenciacion", 
             "redes_nnet", "xgboost", "redes_neuralnet", "regresion_logistica") # Los nombres para identificarlos

funciones <- list(train.svm, train.knn, train.bayes, train.rpart, train.randomForest, train.ada,
                  train.nnet, train.xgboost, train.neuralnet, train.glm) # Las funciones (en orden con respecto a "metodos")

parametros <- list(list(kernel = "linear", probability = FALSE), 
                   list(kmax = 37), list() , list(), list(),
                   list(iter = 20, nu = 1, type = "discrete"),
                   list(size = 100, MaxNWts = 5000, rang = 0.01, decay = 5e-4, maxit = 45, trace = TRUE),
                   list(nrounds = 79, print_every_n = 10, maximize = FALSE , eval_metric = "error"),
                   list(hidden = c(3, 2,6), linear.output = FALSE, threshold = 0.5, stepmax = 1e+06),
                   list()) # Los parametros de cada modelo (en orden con respecto a "metodos")

resultados <- matrix(0, nrow = cantidad.validacion.cruzada, ncol = 10) # ncol la cantidad de modelos a usar
colnames(resultados) <- metodos
names(funciones) <- metodos
names(parametros) <- metodos

tiempo.no.paralelo <- Sys.time()

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    for(metodo in metodos) { # Ejecutamos cada metodo
      .fun <- funciones[[metodo]] # Obtengo la funcion que quiero usar
      params <- parametros[[metodo]] # Obtengo los parametros que quiero usar
      # do.call llama a una funcion con los parametros que le pasemos como lista
      # substitute nos permite poner el nombre de la variable "ttraining" en lugar del valor
      modelo <- do.call(.fun, c(BuenPagador ~ ., data = substitute(ttraining), params))
      prediccion <- predict(modelo, ttesting)
      MC <- confusion.matrix(ttesting, prediccion)
      resultados[i, metodo] <- resultados[i, metodo] + MC["No","No"] # Detección de los NO Pagadores
    }
  }
}

tiempo.no.paralelo <- Sys.time() - tiempo.no.paralelo
```

**Tiempo de ejecución**
```{r}
tiempo.no.paralelo
```

**Graficamos los resultados**
```{r}
par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA, cex = 0.8,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

##

## Versión Paralela

## {.tabset}

### Paquetes

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(caret)
  library(e1071)
  library(kknn)
  library(class)
  library(rpart)
  library(randomForest)
  library(ada)
  library(nnet)
  library(dplyr)
  
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.svm <- 0
  no.knn <- 0
  no.bayes <- 0
  no.arbol <- 0
  no.bosque <- 0
  no.potenciacion <- 0
  no.red <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- svm(BuenPagador ~ ., data = ttraining, kernel = "linear")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.svm <- no.svm + MC["No", "No"]
    
    modelo <- train.kknn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.knn <- no.knn + MC["No", "No"]
    
    modelo <- naiveBayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.bayes <- no.bayes + MC["No", "No"]
    
    modelo = rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting, type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.arbol <- no.arbol + MC["No", "No"]
    
    modelo <- randomForest(BuenPagador ~ ., data = ttraining, importance = TRUE)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.bosque <- no.bosque + MC["No", "No"]
    
    modelo <- ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.potenciacion <- no.potenciacion + MC["No", "No"]
    
    modelo <- nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
                   decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting[, -6], type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, factor(prediccion, levels = levels(Actual)), exclude = FALSE)
    # Detección de los No Pagadores
    no.red <- no.red + MC["No", "No"]
  }
  
  return(data.frame("svm"     = no.svm, 
                    "knn"     = no.knn, 
                    "bayes"   = no.bayes, 
                    "arboles" = no.arbol,
                    "bosques" = no.bosque,
                    "potenciacion" = no.potenciacion,
                    "redes_nnet" = no.red))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

**Tiempo de ejecución**
```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Graficamos los resultados**
```{r}
par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA, cex = 0.8,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

### trainR

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(caret)
  library(trainR)
  
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.svm <- 0
  no.knn <- 0
  no.bayes <- 0
  no.arbol <- 0
  no.bosque <- 0
  no.potenciacion <- 0
  no.red <- 0
  no.xg  <- 0
  no.red.neu <- 0
  no.glm <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- train.svm(BuenPagador ~ ., data = ttraining, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.svm <- no.svm + MC["No", "No"]
    
    modelo <- train.knn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.knn <- no.knn + MC["No", "No"]
    
    modelo <- train.bayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.bayes <- no.bayes + MC["No", "No"]
    
    modelo = train.rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.arbol <- no.arbol + MC["No", "No"]
    
    modelo <- train.randomForest(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.bosque <- no.bosque + MC["No", "No"]
    
    modelo <- train.ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.potenciacion <- no.potenciacion + MC["No", "No"]

    modelo <- train.nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01,
               decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.red <- no.red + MC["No", "No"]
     
    modelo <- train.xgboost(BuenPagador ~ ., data = ttraining, nrounds = 79,
                        print_every_n = 10, maximize = F , eval_metric = "error")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.xg <- no.xg + MC["No", "No"]

    modelo <- train.neuralnet(BuenPagador ~., data = ttraining, hidden = c(3, 2, 6),
                          linear.output = FALSE, threshold = 0.5, stepmax = 1e+06)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.red.neu <- no.red.neu + MC["No", "No"]

    modelo <- train.glm(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.glm <- no.glm + MC["No", "No"]
  }
  
  return(list("svm"     = no.svm, 
              "knn"     = no.knn, 
              "bayes"   = no.bayes, 
              "arboles" = no.arbol,
              "bosques" = no.bosque,
              "potenciacion" = no.potenciacion,
              "redes_nnet" = no.red,
              "xgboost" = no.xg,
              "redes_neuralnet" = no.red.neu,
              "regresion_logistica" = no.glm))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

**Tiempo de ejecución**
```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Graficamos los resultados**
```{r}
par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA, cex = 0.8,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

##

# Veamos el error 

## {.tabset}

### Paquetes

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(caret)
  library(e1071)
  library(kknn)
  library(class)
  library(rpart)
  library(randomForest)
  library(ada)
  library(nnet)
  library(dplyr)
  
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  error.svm <- 0
  error.knn <- 0
  error.bayes <- 0
  error.arbol <- 0
  error.bosque <- 0
  error.potenciacion <- 0
  error.red <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- svm(BuenPagador ~ ., data = ttraining, kernel = "linear")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección del error global
    error.svm <- error.svm + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.kknn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección del error global
    error.knn <- error.knn + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- naiveBayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección del error global
    error.bayes <- error.bayes + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo = rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting, type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección del error global
    error.arbol <- error.arbol + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- randomForest(BuenPagador ~ ., data = ttraining, importance = TRUE)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección del error global
    error.bosque <- error.bosque + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección del error global
    error.potenciacion <- error.potenciacion + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
                   decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting[, -6], type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, factor(prediccion, levels = levels(Actual)), exclude = FALSE)
    # Detección del error global
    error.red <- error.red + (1 - (sum(diag(MC)) / sum(MC))) * 100
  }
  
  return(data.frame("svm"     = error.svm / cantidad.grupos, 
                    "knn"     = error.knn / cantidad.grupos, 
                    "bayes"   = error.bayes / cantidad.grupos, 
                    "arboles" = error.arbol / cantidad.grupos,
                    "bosques" = error.bosque / cantidad.grupos,
                    "potenciacion" = error.potenciacion / cantidad.grupos,
                    "redes_nnet" = error.red / cantidad.grupos))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

**Tiempo de ejecución**
```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Graficamos los resultados**
```{r}
par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Comparación del Error Global", 
        xlab = "Número de iteración",
        ylab = "Error Global",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA, cex = 0.8,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

### trainR

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(caret)
  library(trainR)
  
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  error.svm <- 0
  error.knn <- 0
  error.bayes <- 0
  error.arbol <- 0
  error.bosque <- 0
  error.potenciacion <- 0
  error.red <- 0
  error.xg  <- 0
  error.red.neu <- 0
  error.glm <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- train.svm(BuenPagador ~ ., data = ttraining, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección del error global
    error.svm <- error.svm + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.knn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección del error global
    error.knn <- error.knn + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.bayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección del error global
    error.bayes <- error.bayes + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo = train.rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección del error global
    error.arbol <- error.arbol + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.randomForest(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección del error global
    error.bosque <- error.bosque + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección del error global
    error.potenciacion <- error.potenciacion + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
               decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección del error global
    error.red <- error.red + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.xgboost(BuenPagador ~ ., data = ttraining, nrounds = 79,
                        print_every_n = 10, maximize = F , eval_metric = "error")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección del error global
    error.xg <- error.xg + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.neuralnet(BuenPagador ~., data = ttraining, hidden = c(3, 2,6), 
                          linear.output = FALSE, threshold = 0.5, stepmax = 1e+06)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección del error global
    error.red.neu <- error.red.neu + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.glm(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección del error global
    error.glm <- error.glm + (1 - (sum(diag(MC)) / sum(MC))) * 100
  }
  
  return(data.frame("svm"     = error.svm /cantidad.grupos, 
                    "knn"     = error.knn /cantidad.grupos, 
                    "bayes"   = error.bayes /cantidad.grupos, 
                    "arboles" = error.arbol /cantidad.grupos, 
                    "bosques" = error.bosque /cantidad.grupos, 
                    "potenciacion" = error.potenciacion /cantidad.grupos, 
                    "redes_nnet" = error.red /cantidad.grupos, 
                    "xgboost" = error.xg /cantidad.grupos, 
                    "redes_neuralnet" = error.red.neu/cantidad.grupos, 
                    "regresion_logistica" = error.glm /cantidad.grupos))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

**Tiempo de ejecución**
```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Graficamos los resultados**
```{r}
par(oma=c(0, 0, 0, 5)) # Hace espacio para la leyenda
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Comparación del Error Global", 
        xlab = "Número de iteración",
        ylab = "Error Global",
        col = rainbow(ncol(resultados)))
legend(par('usr')[2], par('usr')[4], legend = colnames(resultados),bty='n', xpd=NA, cex = 0.8,
       pch=1:ncol(resultados), col = rainbow(ncol(resultados))) # La leyenda
```

##

En problemas reales la validación cruzada solo se ejecuta una vez y con lo modelos debidamente calibrados.

En este caso obtendremos tanto cantidad de No, como el error de cada modelo.

## {.tabset}

### Paquetes

**Se cargan las librerías**
```{r}
library(snow)
library(dplyr)
library(tidyr)
library(tibble)
library(caret)
```

```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5,type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")

metodos <- c("svm", "k_vecinos", "bayes", "arboles", "bosques", "potenciacion", "redes_nnet")
# Los nombres para identificarlos

clusterExport(clp, "metodos")

ignorar <- clusterEvalQ(clp,{
  library(e1071)
  library(kknn)
  library(class)
  library(rpart)
  library(randomForest)
  library(ada)
  library(nnet)
  
  funciones <- list(svm, train.kknn, naiveBayes, rpart, randomForest, ada, nnet)
  # Las funciones (en orden con respecto a "metodos")
  
  parametros <- list(list(kernel = "linear", probability = FALSE), 
                     list(kmax = 37), list() , list(), list(importance = TRUE),
                     list(iter = 20, nu = 1, type = "discrete"),
                     list(size = 100, MaxNWts = 5000, rang = 0.01, decay = 5e-4, maxit = 45, trace = TRUE)) 
  # Los parametros de cada modelo (en orden con respecto a "metodos")
  
  names(funciones) <- metodos
  names(parametros) <- metodos
  
  NULL
})
```


```{r}
cantidad.grupos  <- 10
numero.filas  <- nrow(datos)

grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
df.resultados <- data.frame()

tiempo.paralelo <- Sys.time()

for (k in 1:cantidad.grupos) {
  muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
  ttesting <- datos[muestra, ]
  ttraining <- datos[-muestra, ]
  clusterExport(clp, "ttesting")
  clusterExport(clp, "ttraining")
  
  resultados <- clusterApply(clp, metodos, function(metodo) {
    .fun <- funciones[[metodo]]
    param <- parametros[[metodo]]
    modelo <- do.call(.fun, c(BuenPagador ~ ., data = substitute(ttraining), param))
    if(metodo == "arboles" || metodo == "redes_nnet"){
      prediccion <- predict(modelo, ttesting[, -6], type = "class")
    }else{
      prediccion <- predict(modelo, ttesting[, -6])
    }
    Real <- ttesting[, 6]
    MC <- table(Real, factor(prediccion, levels = levels(Real)), exclude = FALSE)
    error <- (1 - (sum(diag(MC)) / sum(MC))) * 100
    nos <- MC["No", "No"]
    return(data.frame("metodo" = metodo, "error" = error, "nos" = nos))
  })
  
  df.resultados <- rbind(df.resultados, do.call(rbind, resultados))
  
}

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**Los errores serían:**
```{r}
errores <- rowid_to_column(df.resultados) %>% select(rowid, metodo, error) %>% 
           spread(metodo, error, fill = 0) %>% select(-rowid) %>% colSums() %>% 
           as.data.frame() %>% rename("Validacion Cruzada" = ".")
errores <- errores/cantidad.grupos # Los errores se tienen que ponderar
errores
```

**La cantidad de "No" serían:**
```{r}
deteccion.no <- rowid_to_column(df.resultados) %>% select(rowid, metodo, nos) %>% 
                spread(metodo, nos, fill = 0) %>% select(-rowid) %>% colSums() %>% 
                as.data.frame() %>% rename("Validacion Cruzada" = ".")
deteccion.no
```

### trainR

**Se cargan las librerías**
```{r}
library(snow)
library(dplyr)
library(tidyr)
library(tibble)
library(caret)
```

```{r}
setwd("~/Datos(CSV)/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5,type="SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")

metodos <- c("svm", "k_vecinos", "bayes", "arboles", "bosques", "potenciacion", 
           "redes_nnet", "xgboost", "redes_neuralnet", "regresion_logistica")
# Los nombres para identificarlos

clusterExport(clp, "metodos")

ignorar <- clusterEvalQ(clp,{
  library(trainR)

  funciones <- list(train.svm, train.knn, train.bayes, train.rpart, train.randomForest, train.ada,
                    train.nnet, train.xgboost, train.neuralnet, train.glm) 
  # Las funciones (en orden con respecto a "metodos")

  parametros <- list(list(kernel = "linear", probability = FALSE), 
                     list(kmax = 37), list() , list(), list(),
                     list(iter = 20, nu = 1, type = "discrete"),
                     list(size = 100, MaxNWts = 5000, rang = 0.01, decay = 5e-4, maxit = 45, trace = TRUE),
                     list(nrounds = 79, print_every_n = 10, maximize = FALSE , eval_metric = "error"),
                     list(hidden = c(3, 2,6), linear.output = FALSE, threshold = 0.5, stepmax = 1e+06),
                     list()) 
  # Los parametros de cada modelo (en orden con respecto a "metodos")
  
  names(funciones) <- metodos
  names(parametros) <- metodos
  
  NULL
})
```


```{r}
cantidad.grupos <- 10
numero.filas <- nrow(datos)

grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
df.resultados <- data.frame()

tiempo.paralelo <- Sys.time()

for (k in 1:cantidad.grupos) {
  muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
  ttesting <- datos[muestra, ]
  ttraining <- datos[-muestra, ]
  clusterExport(clp, "ttesting")
  clusterExport(clp, "ttraining")
  
  resultados <- clusterApply(clp, metodos, function(metodo) {
    .fun <- funciones[[metodo]]
    param <- parametros[[metodo]]
    modelo <- do.call(.fun, c(BuenPagador ~ ., data = substitute(ttraining), param))
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    error <- (1 - (sum(diag(MC)) / sum(MC))) * 100
    nos <- MC["No", "No"]
    return(data.frame("metodo" = metodo, "error" = error, "nos" = nos))
  })
  
  df.resultados <- rbind(df.resultados, do.call(rbind, resultados))
  
}

tiempo.paralelo <- Sys.time()-tiempo.paralelo

stopCluster(clp)
```

```{r}
 tiempo.paralelo
```

**Los errores serían:**
```{r}
errores <- rowid_to_column(df.resultados) %>% select(rowid, metodo, error) %>% 
           spread(metodo, error, fill = 0) %>% select(-rowid) %>% colSums() %>% 
           as.data.frame() %>% rename("Validacion Cruzada" = ".")
errores <- errores / cantidad.grupos # Los errores se tienen que ponderar
errores
```

**La cantidad de "No" serían:**
```{r}
deteccion.no <- rowid_to_column(df.resultados) %>% select(rowid,metodo,nos) %>% 
                spread(metodo, nos, fill = 0) %>% select(-rowid) %>% colSums() %>% 
                as.data.frame() %>% rename("Validacion Cruzada" = ".")
deteccion.no
```

##

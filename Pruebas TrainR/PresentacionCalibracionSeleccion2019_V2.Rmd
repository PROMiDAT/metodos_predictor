---
output:
  html_document:
    highlight: haddock
    theme: cerulean
---

![](logo.jpg)

# Calibración y Selección de Modelos en Paralelo

## Calibrando el método "Máquinas Vectoriales de Soporte" para los datos de Scoring de Crédito

## Versión NO Paralela

#### Para esto usaremos archivo "MuestraCredito5000V2.csv""

#### En el caso del Scoring de Crédito lo que más interesa en detectar a los NO pagadores, por esa razón ejecutaremos 5 veces la validación cruzada usando 10 grupos. En cada paso de la valización cruzada vamos sumando los no pagadores detectados, luego para cada ejecución de la valizadación cruzada almacenamos la detección de los no pagadores en una entrada del vector respectivo al método para luego hacer un gráfico comparativo.

#### Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel Radial.

```{r eje3,comment=NA}
# El siguiente paquete es usado para generar los grupos al azar
suppressMessages(library(caret)) 
suppressWarnings(suppressMessages(library(e1071)))
setwd("~/Google Drive/MDCurso/Datos")
datos <- read.csv("MuestraCredito5000V2.csv",sep = ";",header=T)
# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
n <- dim(datos)[1]
deteccion.no.radial <- rep(0, 5)
deteccion.no.linear <- rep(0, 5)
deteccion.no.polynomial <- rep(0, 5)
deteccion.no.sigmoid <- rep(0, 5)
# Validación cruzada 5 veces
tiempo.usual <- system.time(
for (i in 1:5) {
  grupos <- createFolds(1:n, 10)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for (k in 1:10) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.radial <- no.radial + MC[1, 1]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.linear <- no.linear + MC[1, 1]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC[1, 1]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC[1, 1]
  }
  deteccion.no.radial[i] <- no.radial
  deteccion.no.linear[i] <- no.linear
  deteccion.no.polynomial[i] <- no.polynomial
  deteccion.no.sigmoid[i] <- no.sigmoid
}
)
plot(deteccion.no.radial, col = "magenta", type = "b", 
     ylim = c(min(deteccion.no.radial,
                  deteccion.no.linear, deteccion.no.polynomial, 
                  deteccion.no.sigmoid), max(deteccion.no.radial,
                                             deteccion.no.linear, deteccion.no.polynomial, 
                                             deteccion.no.sigmoid) + 200),
     main = "Detección del NO pagador en SVM", 
     xlab = "Número de iteración",
     ylab = "Cantidad de NO pagadores detectados")
points(deteccion.no.linear, col = "blue", type = "b")
points(deteccion.no.polynomial, col = "red", type = "b")
points(deteccion.no.sigmoid, col = "green", type = "b")
legend("topright", legend = c("Radial", "Linear", "Polynomial", "Sigmoid"),
       col = c("magenta", "blue", "red", "green"), lty = 1, lwd = 1)

tiempo.usual
```


## Versión Paralela

```{r eje4,comment=NA}
# Proceso Paralelo
suppressWarnings(suppressMessages(library(snow)))
clp <- makeCluster(5, type = "SOCK")
# Constructor del cluster
ignore <- clusterEvalQ(clp, {
      suppressWarnings(suppressMessages(library(e1071)))
      suppressWarnings(suppressMessages(library(formula.tools)))

      ejecutar.prediccion <- function(datos, formula, muestra,metodo, ...) {
        ttesting <- datos[muestra, ]
        taprendizaje <- datos[-muestra, ]
        modelo <- metodo(formula, data = taprendizaje, ...)
        prediccion <- predict(modelo, ttesting, type = "class")
        # Obtiene la variable dependiente de la fórmula. Se ocupa
        # usar el paquete formula.tools
        variable.discriminante <- lhs.vars(formula)
        MC <- table(ttesting[, variable.discriminante], prediccion)
        return(MC)
      }
})

suppressMessages(library(caret))
setwd("~/Google Drive/MDCurso/Datos")
setwd("~/Google Drive/MDCurso/Datos")
datos <- read.csv("MuestraCredito5000V2.csv",sep = ";",header=T)
# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
n <- dim(datos)[1]
algoritmos <- c("radial", "linear", "polynomial", "sigmoid")
deteccion.no.radial <- rep(0, 5)
deteccion.no.linear <- rep(0, 5)
deteccion.no.polynomial <- rep(0, 5)
deteccion.no.sigmoid <- rep(0, 5)
tiempo.paralelo <- system.time(
  for (i in 1:5) {
      grupos <- createFolds(1:n, 10)
      no.radial <- 0
      no.linear <- 0
      no.polynomial <- 0
      no.sigmoid <- 0
      for (k in 1:10) {
            muestra <- grupos[[k]]
            ### Inserta estas 2 variables en cada peón
            clusterExport(clp, "datos")
            clusterExport(clp, "muestra")
            resultado <- clusterApply(clp, algoritmos, function(pkernels) {
                  MC <- ejecutar.prediccion(datos, BuenPagador ~ .,muestra, svm, kernel = pkernels)
                  no.val <- MC[1, 1]
                  valores <- list(Tipo <- pkernels, Resultado <- no.val,MC <- MC)
                  valores
            })
            for (j in 1:length(algoritmos)) {
              if (resultado[[j]][[1]] == "radial") 
                 no.radial <- no.radial + resultado[[j]][[2]] 
              else if (resultado[[j]][[1]] == "linear")
                 no.linear <- no.linear + resultado[[j]][[2]] 
              else if (resultado[[j]][[1]] == "polynomial")
                 no.polynomial <- no.polynomial + resultado[[j]][[2]] 
              else if (resultado[[j]][[1]] == "sigmoid")
                 no.sigmoid <- no.sigmoid + resultado[[j]][[2]]
            }
      }
      deteccion.no.radial[i] <- no.radial
      deteccion.no.linear[i] <- no.linear
      deteccion.no.polynomial[i] <- no.polynomial
      deteccion.no.sigmoid[i] <- no.sigmoid
  }
)
stopCluster(clp)
plot(deteccion.no.radial, col = "magenta", type = "b", ylim = 
       c(min(deteccion.no.radial,deteccion.no.linear, deteccion.no.polynomial, deteccion.no.sigmoid),
max(deteccion.no.radial, deteccion.no.linear, deteccion.no.polynomial,
deteccion.no.sigmoid) + 200), main = "Detección del NO pagador en SVM",
xlab = "Número de iteración", ylab = "Cantidad de NO pagadores detectados")
points(deteccion.no.linear, col = "blue", type = "b")
points(deteccion.no.polynomial, col = "red", type = "b")
points(deteccion.no.sigmoid, col = "green", type = "b")
legend("topright", legend = c("Radial", "Linear", "Polynomial",
"Sigmoid"), col = c("magenta", "blue", "red", "green"), lty = 1,lwd = 1)

tiempo.paralelo
```

## Seleccionando el mejor Método para los datos de Scoring de Crédito

## Versión NO Paralela

```{r eje6,comment=NA}
library(caret)
library(snow)
library(e1071)
library(kknn)
library(class)
library(rpart)
library(randomForest)
library(ada)
library(nnet)
library(formula.tools)
library(magrittr)
library(dplyr)

setwd("~/Google Drive/MDCurso/Datos")
datos <- read.csv("MuestraCredito5000V2.csv",sep = ";",header=T)
# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
n <- dim(datos)[1]
str(datos)

# Versión NO paralela

n <- dim(datos)[1]
deteccion.no.svm <- rep(0, 5)
deteccion.no.knn <- rep(0, 5)
deteccion.no.bayes <- rep(0, 5)
deteccion.no.arbol <- rep(0, 5)
deteccion.no.bosque <- rep(0, 5)
deteccion.no.potenciacion <- rep(0, 5)
deteccion.no.red <- rep(0, 5)

# Medimos tiempo de ejecución
t.no.paralelo <- system.time(
  # Validación cruzada 5 veces
  for (i in 1:5) {
    grupos <- createFolds(1:n, 10) # Crea los 10 grupos
    no.svm <- 0
    no.knn <- 0
    no.bayes <- 0
    no.arbol <- 0
    no.bosque <- 0
    no.potenciacion <- 0
    no.red <- 0
    # Este ciclo es el que hace validación cruzada con 10 grupos
    for (k in 1:10) {
      muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
      ttesting <- datos[muestra, ]
      ttraining <- datos[-muestra, ]
      
      modelo <- svm(BuenPagador ~ ., data = ttraining, kernel = "radial")
      prediccion <- predict(modelo, ttesting)
      Actual <- ttesting[, 6]
      MC <- table(Actual, prediccion)
      # Detección de los No Pagadores
      no.svm <- no.svm + MC[1, 1]
      
      modelo <- train.kknn(BuenPagador ~ ., data = ttraining, kmax = 37)
      prediccion <- predict(modelo, ttesting[, -6])
      Actual <- ttesting[, 6]
      MC <- table(Actual, prediccion)
      # Detección de los No Pagadores
      no.knn <- no.knn + MC[1, 1]
      
      modelo <- naiveBayes(BuenPagador ~ ., data = ttraining)
      prediccion <- predict(modelo, ttesting[, -6])
      Actual <- ttesting[, 6]
      MC <- table(Actual, prediccion)
      # Detección de los No Pagadores
      no.bayes <- no.bayes + MC[1, 1]
      
      modelo = rpart(BuenPagador ~ ., data = ttraining)
      prediccion <- predict(modelo, ttesting, type = "class")
      Actual <- ttesting[, 6]
      MC <- table(Actual, prediccion)
      # Detección de los No Pagadores
      no.arbol <- no.arbol + MC[1, 1]
      
      modelo <- randomForest(BuenPagador ~ ., data = ttraining, importance = TRUE)
      prediccion <- predict(modelo, ttesting[, -6])
      Actual <- ttesting[, 6]
      MC <- table(Actual, prediccion)
      # Detección de los No Pagadores
      no.bosque <- no.bosque + MC[1, 1]
      
      modelo <- ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
      prediccion <- predict(modelo, ttesting[, -6])
      Actual <- ttesting[, 6]
      MC <- table(Actual, prediccion)
      # Detección de los No Pagadores
      no.potenciacion <- no.potenciacion + MC[1, 1]
      
      modelo <- nnet(BuenPagador ~ ., data = ttraining, size = 5, rang = 0.1, decay = 5e-04, maxit = 100, trace = FALSE)
      prediccion <- predict(modelo, ttesting[, -6], type = "class")
      Actual <- ttesting[, 6]
      MC <- table(Actual, prediccion)
      # Detección de los No Pagadores
      no.red <- no.red + MC[1, 1]
    }
    deteccion.no.svm[i] <- no.svm
    deteccion.no.knn[i] <- no.knn
    deteccion.no.bayes[i] <- no.bayes
    deteccion.no.arbol[i] <- no.arbol
    deteccion.no.bosque[i] <- no.bosque
    deteccion.no.potenciacion[i] <- no.potenciacion
    deteccion.no.red[i] <- no.red
  }
)

# Graficamos los resultados
plot(deteccion.no.svm, col = "magenta", type = "b", ylim = c(min(deteccion.no.svm,deteccion.no.knn,deteccion.no.bayes,deteccion.no.arbol,deteccion.no.bosque,deteccion.no.potenciacion,deteccion.no.red), max(deteccion.no.svm, deteccion.no.knn, deteccion.no.bayes, deteccion.no.arbol,deteccion.no.bosque,deteccion.no.potenciacion,deteccion.no.red)), xlim = c(1, 7), main = "Detección del No pagador", xlab = "Número de iteración", ylab = "Cantidad de No Pagadores detectados")
points(deteccion.no.knn, col = "blue", type = "b")
points(deteccion.no.arbol, col = "red", type = "b")
points(deteccion.no.bosque, col = "green", type = "b")
points(deteccion.no.bayes, col = "lightpink2", type = "b")
points(deteccion.no.potenciacion, col = "orange3", type = "b")
points(deteccion.no.red, col = "rosybrown4", type = "b")
legend("topright", legend = c("SVM","KNN","Árbol","Bosque","Bayes","Potenciación","Red Neuronal"), col = c("magenta","blue","red","green","lightpink2","orange3","rosybrown4"), lty = 1, lwd = 2)

# Tiempo de ejecución
t.no.paralelo
```

## Versión Paralela

```{r eje7,comment=NA}
metodos <- c("svm", "train.kknn", "naiveBayes", "rpart", "randomForest", "ada", "nnet")

# Seguidamente cargamos la función general usada en clase para obtener la matriz de confusión de cualquier modelo. 
# Debido a que todos los predict son diferentes a esta función se le agregan las siguientes modificaciones.
# Condicional para el parámetro class en algunos métodos.
# Condicional para eliminar la variable a predecir en la tabla de testing en algunos métodos.

# Método nnet
# prediccion <- predict(modelo, ttesting[, -6], type = "class")
# Método rpart
# prediccion <- predict(modelo, ttesting, type = "class")
# Método kknn
# prediccion <- predict(modelo, ttesting[, -6])
# Método naiveBayes
# prediccion <- predict(modelo, ttesting[, -6])
# Método randomForest
# prediccion <- predict(modelo, ttesting[, -6])
# Método ada
# prediccion <- predict(modelo, ttesting[, -6])
# Método svm
# prediccion <- predict(modelo, ttesting)

ejecutar.prediccion <- function(datos, formula, muestra, metodo, ...) {
  ttesting <- datos[muestra, ]
  ttraining <- datos[-muestra, ]
  modelo <- metodo(formula, data = ttraining, ...)
  # Obtiene la variable dependiente de la fórmula
  va.predecir <- lhs.vars(formula)
  
  if(list(metodo) %in% list(nnet))
    prediccion <- predict(modelo, ttesting %>% select_(.dots = paste("-", va.predecir)), type = "class")
  
  if(list(metodo) %in% list(rpart))  
    prediccion <- predict(modelo, ttesting, type = "class")

  if(list(metodo) %in% list(train.kknn, randomForest, ada, naiveBayes))
    prediccion <- predict(modelo, ttesting %>% select_(.dots = paste("-", va.predecir)))
    
  if(list(metodo) %in% list(svm))
    prediccion <- predict(modelo, ttesting)
  
  MC <- table(ttesting[, va.predecir], prediccion)
  return(MC)
}

# La siguiente función permite fijar parámetros específicos para cada método, lo cual es útil para usar otros parámetros que no sean los default.

ejecutar.prediccion.particular <- function(datos, formula, muestra, metodo) {
  if(list(metodo) %in% list(svm)){return(ejecutar.prediccion(datos, formula, muestra, metodo, kernel = "radial"))}
  if(list(metodo) %in% list(train.kknn)){return(ejecutar.prediccion(datos, formula, muestra, metodo, kmax = 37))}
  if(list(metodo) %in% list(naiveBayes)){return(ejecutar.prediccion(datos, formula, muestra, metodo))}
  if(list(metodo) %in% list(rpart)){return(ejecutar.prediccion(datos, formula, muestra, metodo))}
  if(list(metodo) %in% list(randomForest)){return(ejecutar.prediccion(datos, formula, muestra, metodo, importance = TRUE))}
  if(list(metodo) %in% list(ada)){return(ejecutar.prediccion(datos, formula, muestra, metodo, iter = 20, nu = 1, type = "discrete"))}
  if(list(metodo) %in% list(nnet)){return(ejecutar.prediccion(datos, formula, muestra, metodo, size = 5, rang = 0.1, decay = 5e-04, maxit = 100, trace = FALSE))}
}

# Creamos peones
peones <- parallel::detectCores()
peones

# Inicializamos clusters
cl <- makeCluster(peones, type = "SOCK")

# Exportamos paquetes a los procesadores
ignore <- clusterEvalQ(cl, {library(dplyr)
  library(e1071)
  library(kknn)
  library(class)
  library(rpart)
  library(randomForest)
  library(ada)
  library(nnet)
  library(formula.tools); NULL})

# Exportamos los datos y las funciones a los procesadores
clusterExport(cl, list("datos", "ejecutar.prediccion", "ejecutar.prediccion.particular"))

# Corremos la Validación Cruzada

n <- dim(datos)[1]
deteccion.no.svm <- rep(0, 5)
deteccion.no.knn <- rep(0, 5)
deteccion.no.bayes <- rep(0, 5)
deteccion.no.arbol <- rep(0, 5)
deteccion.no.bosque <- rep(0, 5)
deteccion.no.potenciacion <- rep(0, 5)
deteccion.no.red <- rep(0, 5)

# Medimos tiempo de ejecución
t.paralelo <- system.time(
  # Validación cruzada 5 veces
  for (i in 1:5) {
    grupos <- createFolds(1:n, 10)  # Crea los 10 grupos
    no.svm <- 0
    no.knn <- 0
    no.bayes <- 0
    no.arbol <- 0
    no.bosque <- 0
    no.potenciacion <- 0
    no.red <- 0
    # Este ciclo es el que hace validación cruzada con 10 grupos
    for (k in 1:10) {
      muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
      # Exportamos la muestra a los procesadores
      clusterExport(cl, "muestra")
      resultado <- clusterApply(cl, metodos, function(metodo) {
        MC <- ejecutar.prediccion.particular(datos = datos, formula = BuenPagador~., muestra = muestra, metodo = eval(parse(text = metodo)))
        no.val <- MC[1, 1]
        valores <- list(Tipo = metodo, Resultado = no.val, MC = MC)
        return(valores)
      })
      for (j in seq_along(metodos)) {
        if (resultado[[j]][[1]] == "svm")
          no.svm <- no.svm + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "train.kknn")
          no.knn <- no.knn + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "naiveBayes")
          no.bayes <- no.bayes + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "rpart")
          no.arbol <- no.arbol + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "randomForest")
          no.bosque <- no.bosque + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "ada")
          no.potenciacion <- no.potenciacion + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "nnet")
          no.red <- no.red + resultado[[j]][[2]]
      }
    }
    deteccion.no.svm[i] <- no.svm
    deteccion.no.knn[i] <- no.knn
    deteccion.no.bayes[i] <- no.bayes
    deteccion.no.arbol[i] <- no.arbol
    deteccion.no.bosque[i] <- no.bosque
    deteccion.no.potenciacion[i] <- no.potenciacion
    deteccion.no.red[i] <- no.red
  }
)
# Detenemos cluster
stopCluster(cl)

# Graficamos los resultados
plot(deteccion.no.svm, col = "magenta", type = "b", ylim = c(min(deteccion.no.svm,deteccion.no.knn,deteccion.no.bayes,deteccion.no.arbol,deteccion.no.bosque,deteccion.no.potenciacion,deteccion.no.red), max(deteccion.no.svm, deteccion.no.knn, deteccion.no.bayes, deteccion.no.arbol,deteccion.no.bosque,deteccion.no.potenciacion,deteccion.no.red)), xlim = c(1, 7), main = "Detección del No pagador", xlab = "Número de iteración", ylab = "Cantidad de No Pagadores detectados")
points(deteccion.no.knn, col = "blue", type = "b")
points(deteccion.no.arbol, col = "red", type = "b")
points(deteccion.no.bosque, col = "green", type = "b")
points(deteccion.no.bayes, col = "lightpink2", type = "b")
points(deteccion.no.potenciacion, col = "orange3", type = "b")
points(deteccion.no.red, col = "rosybrown4", type = "b")
legend("topright", legend = c("SVM","KNN","Árbol","Bosque","Bayes","Potenciación","Red Neuronal"), col = c("magenta","blue","red","green","lightpink2","orange3","rosybrown4"), lty = 1, lwd = 2)

# Tiempo paralelo
t.paralelo
```

## Veamos el error (Versión Paralela)

```{r eje8,comment=NA}
metodos <- c("svm", "train.kknn", "naiveBayes", "rpart", "randomForest", "ada", "nnet")

# Seguidamente cargamos la función general usada en clase para obtener la matriz de confusión de cualquier modelo. 
# Debido a que todos los predict son diferentes a esta función se le agregan las siguientes modificaciones.
# Condicional para el parámetro class en algunos métodos.
# Condicional para eliminar la variable a predecir en la tabla de testing en algunos métodos.

# Método nnet
# prediccion <- predict(modelo, ttesting[, -6], type = "class")
# Método rpart
# prediccion <- predict(modelo, ttesting, type = "class")
# Método kknn
# prediccion <- predict(modelo, ttesting[, -6])
# Método naiveBayes
# prediccion <- predict(modelo, ttesting[, -6])
# Método randomForest
# prediccion <- predict(modelo, ttesting[, -6])
# Método ada
# prediccion <- predict(modelo, ttesting[, -6])
# Método svm
# prediccion <- predict(modelo, ttesting)

ejecutar.prediccion <- function(datos, formula, muestra, metodo, ...) {
  ttesting <- datos[muestra, ]
  ttraining <- datos[-muestra, ]
  modelo <- metodo(formula, data = ttraining, ...)
  # Obtiene la variable dependiente de la fórmula
  va.predecir <- lhs.vars(formula)
  
  if(list(metodo) %in% list(nnet))
    prediccion <- predict(modelo, ttesting %>% select_(.dots = paste("-", va.predecir)), type = "class")
  
  if(list(metodo) %in% list(rpart))  
    prediccion <- predict(modelo, ttesting, type = "class")

  if(list(metodo) %in% list(train.kknn, randomForest, ada, naiveBayes))
    prediccion <- predict(modelo, ttesting %>% select_(.dots = paste("-", va.predecir)))
    
  if(list(metodo) %in% list(svm))
    prediccion <- predict(modelo, ttesting)
  
  MC <- table(ttesting[, va.predecir], prediccion)
  return(MC)
}

# La siguiente función permite fijar parámetros específicos para cada método, lo cual es útil para usar otros parámetros que no sean los default.

ejecutar.prediccion.particular <- function(datos, formula, muestra, metodo) {
  if(list(metodo) %in% list(svm)){return(ejecutar.prediccion(datos, formula, muestra, metodo, kernel = "radial"))}
  if(list(metodo) %in% list(train.kknn)){return(ejecutar.prediccion(datos, formula, muestra, metodo, kmax = 37))}
  if(list(metodo) %in% list(naiveBayes)){return(ejecutar.prediccion(datos, formula, muestra, metodo))}
  if(list(metodo) %in% list(rpart)){return(ejecutar.prediccion(datos, formula, muestra, metodo))}
  if(list(metodo) %in% list(randomForest)){return(ejecutar.prediccion(datos, formula, muestra, metodo, importance = TRUE))}
  if(list(metodo) %in% list(ada)){return(ejecutar.prediccion(datos, formula, muestra, metodo, iter = 20, nu = 1, type = "discrete"))}
  if(list(metodo) %in% list(nnet)){return(ejecutar.prediccion(datos, formula, muestra, metodo, size = 5, rang = 0.1, decay = 5e-04, maxit = 100, trace = FALSE))}
}

# Creamos peones
peones <- parallel::detectCores()
peones

# Inicializamos clusters
cl <- makeCluster(peones, type = "SOCK")

# Exportamos paquetes a los procesadores
ignore <- clusterEvalQ(cl, {library(dplyr)
  library(e1071)
  library(kknn)
  library(class)
  library(rpart)
  library(randomForest)
  library(ada)
  library(nnet)
  library(formula.tools); NULL})

# Exportamos los datos y las funciones a los procesadores
clusterExport(cl, list("datos", "ejecutar.prediccion", "ejecutar.prediccion.particular"))

# Corremos la Validación Cruzada

n <- dim(datos)[1]
deteccion.error.svm <- rep(0, 5)
deteccion.error.knn <- rep(0, 5)
deteccion.error.bayes <- rep(0, 5)
deteccion.error.arbol <- rep(0, 5)
deteccion.error.bosque <- rep(0, 5)
deteccion.error.potenciacion <- rep(0, 5)
deteccion.error.red <- rep(0, 5)

# Medimos tiempo de ejecución
t.paralelo <- system.time(
  # Validación cruzada 5 veces
  for (i in 1:5) {
    grupos <- createFolds(1:n, 10)  # Crea los 10 grupos
    error.svm <- 0
    error.knn <- 0
    error.bayes <- 0
    error.arbol <- 0
    error.bosque <- 0
    error.potenciacion <- 0
    error.red <- 0
    # Este ciclo es el que hace validación cruzada con 10 grupos
    for (k in 1:10) {
      muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
      # Exportamos la muestra a los procesadores
      clusterExport(cl, "muestra")
      resultado <- clusterApply(cl, metodos, function(metodo) {
        MC <- ejecutar.prediccion.particular(datos = datos, formula = BuenPagador~., muestra = muestra, metodo = eval(parse(text = metodo)))
        error.val <- (1 - (sum(diag(MC)) / sum(MC))) * 100
        valores <- list(Tipo = metodo, Resultado = error.val, MC = MC)
        return(valores)
      })
      for (j in seq_along(metodos)) {
        if (resultado[[j]][[1]] == "svm")
          error.svm <- error.svm + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "train.kknn")
          error.knn <- error.knn + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "naiveBayes")
          error.bayes <- error.bayes + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "rpart")
          error.arbol <- error.arbol + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "randomForest")
          error.bosque <- error.bosque + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "ada")
          error.potenciacion <- error.potenciacion + resultado[[j]][[2]]
        else if (resultado[[j]][[1]] == "nnet")
          error.red <- error.red + resultado[[j]][[2]]
      }
    }
    deteccion.error.svm[i] <- error.svm/10
    deteccion.error.knn[i] <- error.knn/10
    deteccion.error.bayes[i] <- error.bayes/10
    deteccion.error.arbol[i] <- error.arbol/10
    deteccion.error.bosque[i] <- error.bosque/10
    deteccion.error.potenciacion[i] <- error.potenciacion/10
    deteccion.error.red[i] <- error.red/10
  }
)
# Detenemos cluster
stopCluster(cl)

# Graficamos los resultados
plot(deteccion.error.svm, col = "magenta", type = "b", ylim = c(min(deteccion.error.svm,deteccion.error.knn,deteccion.error.bayes,deteccion.error.arbol,deteccion.error.bosque,deteccion.error.potenciacion,deteccion.error.red), max(deteccion.error.svm, deteccion.error.knn, deteccion.error.bayes, deteccion.error.arbol,deteccion.error.bosque,deteccion.error.potenciacion,deteccion.error.red)), xlim = c(1, 7), main = "Comparación del Error Global", xlab = "Número de iteración", ylab = "Error Global")
points(deteccion.error.knn, col = "blue", type = "b")
points(deteccion.error.arbol, col = "red", type = "b")
points(deteccion.error.bosque, col = "green", type = "b")
points(deteccion.error.bayes, col = "lightpink2", type = "b")
points(deteccion.error.potenciacion, col = "orange3", type = "b")
points(deteccion.error.red, col = "rosybrown4", type = "b")
legend("topright", legend = c("SVM","KNN","Árbol","Bosque","Bayes","Potenciación","Red Neuronal"), col = c("magenta","blue","red","green","lightpink2","orange3","rosybrown4"), lty = 1, lwd = 2)

# Tiempo paralelo
t.paralelo
```

---
output:
  html_document: 
    df_print: paged
    highlight: haddock
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = NA, fig.width = 18, fig.height = 15)
```

![](logo.jpg)

# Calibración y Selección de Modelos en Paralelo

## Calibrando el método "Máquinas Vectoriales de Soporte" para los datos de Scoring de Crédito

## Versión NO Paralela

#### Para esto usaremos archivo "MuestraCredito5000V2.csv""

**En el caso del Scoring de Crédito lo que más interesa en detectar a los NO pagadores, por esa razón ejecutaremos 5 veces la validación cruzada usando 10 grupos. En cada paso de la valización cruzada vamos sumando los no pagadores detectados, luego para cada ejecución de la valizadación cruzada almacenamos la detección de los no pagadores en una entrada del vector respectivo al método para luego hacer un gráfico comparativo.**

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

## {.tabset}

### Paquete e1071

**Se cargan las librerías**
```{r}
library(caret)
library(e1071)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.radial <- c()
deteccion.no.linear <- c()
deteccion.no.polynomial <- c()
deteccion.no.sigmoid <- c()

tiempo.usual <- Sys.time() 

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  deteccion.no.radial[i] <- no.radial
  deteccion.no.linear[i] <- no.linear
  deteccion.no.polynomial[i] <- no.polynomial
  deteccion.no.sigmoid[i] <- no.sigmoid
}

tiempo.usual <- Sys.time() -  tiempo.usual
```

```{r}
tiempo.usual
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**

```{r}
resultados <- data.frame("radial" = deteccion.no.radial,
                "linear" = deteccion.no.linear,
                "polynomial" = deteccion.no.polynomial,
                "sigmoid" = deteccion.no.sigmoid)

matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

### Paquete trainR

**Se cargan las librerías**
```{r}
library(caret)
library(trainR)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.radial <- c()
deteccion.no.linear <- c()
deteccion.no.polynomial <- c()
deteccion.no.sigmoid <- c()

tiempo.usual <- Sys.time()

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  deteccion.no.radial[i] <- no.radial
  deteccion.no.linear[i] <- no.linear
  deteccion.no.polynomial[i] <- no.polynomial
  deteccion.no.sigmoid[i] <- no.sigmoid
}

tiempo.usual <- Sys.time() - tiempo.usual
```

```{r}
tiempo.usual
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**

```{r}
resultados <- data.frame("radial" = deteccion.no.radial,
                "linear" = deteccion.no.linear,
                "polynomial" = deteccion.no.polynomial,
                "sigmoid" = deteccion.no.sigmoid)

matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

**Otra forma de hacerlo es:**

**Se cargan las librerías**
```{r}
library(caret)
library(trainR)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10
kernels <- c("radial", "linear", "polynomial", "sigmoid")

resultados <- matrix(0, nrow = cantidad.validacion.cruzada, ncol = 4) # ncol la cantidad de modelos a usar
colnames(resultados) <- kernels # opcional

tiempo.usual <- Sys.time()

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    for(kernel in kernels) {
      modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = kernel, probability = FALSE)
      prediccion <- predict(modelo, ttesting)
      MC <- confusion.matrix(ttesting, prediccion)
      resultados[i, kernel] <- resultados[i, kernel] + MC["No","No"] # Detección de los NO Pagadores
    }
  }
}

tiempo.usual <- Sys.time() - tiempo.usual

```

```{r}
tiempo.usual
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
matplot(resultados, type="b",lty = 1, lwd = 1,
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados")
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1, horiz = TRUE, col = 1:4)
```

##

## Versión Paralela

## {.tabset}

### Paquete e1071

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")

cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(e1071)
  library(caret)
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  return(list("radial"     = no.radial, 
              "linear"     = no.linear, 
              "polynomial" = no.polynomial, 
              "sigmoid"    = no.sigmoid))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados) # Unimos cada lista
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

### Paquete trainR

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(trainR)
  library(caret)
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  return(list("radial"     = no.radial, 
              "linear"     = no.linear, 
              "polynomial" = no.polynomial, 
              "sigmoid"    = no.sigmoid))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

**Otra forma de hacerlo es:**

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5
clusterExport(clp, "cantidad.validacion.cruzada")

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(trainR)
  library(caret)
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  kernels <- c("radial", "linear", "polynomial", "sigmoid")
  
  resultados <- matrix(0, nrow = cantidad.validacion.cruzada, ncol = 4) # ncol la cantidad de modelos a usar
  colnames(resultados) <- kernels # opcional

  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    for(kernel in kernels) {
      modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = kernel, probability = FALSE)
      prediccion <- predict(modelo, ttesting)
      MC <- confusion.matrix(ttesting, prediccion)
      resultados[indice, kernel] <- resultados[indice, kernel] + MC["No","No"] # Detección de los NO Pagadores
    }
  }
  return(resultados)
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de matrices, debemos de convertirlo para manejarlo mejor**

```{r}
resultados <- Reduce("+", resultados)
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

##


# Seleccionando el mejor método para los datos de Scoring de Crédito

## Versión NO Paralela

## {.tabset}

### Paquetes

**Se cargan las librerías**
```{r}
library(caret)
library(e1071)
library(kknn)
library(class)
library(rpart)
library(randomForest)
library(ada)
library(nnet)
library(magrittr)
library(dplyr)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.svm <- c()
deteccion.no.knn <- c()
deteccion.no.bayes <- c()
deteccion.no.arbol <- c()
deteccion.no.bosque <- c()
deteccion.no.potenciacion <- c()
deteccion.no.red <- c()

# Medimos tiempo de ejecución
tiempo.no.paralelo <- Sys.time()

# Validación cruzada 5 veces
for (i in 1:cantidad.validacion.cruzada) {
  grupos <- createFolds(1:numero.filas, cantidad.grupos) # Crea los 10 grupos
  no.svm <- 0
  no.knn <- 0
  no.bayes <- 0
  no.arbol <- 0
  no.bosque <- 0
  no.potenciacion <- 0
  no.red <- 0
  
  # Este ciclo es el que hace validación cruzada con 10 grupos
  for (k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- svm(BuenPagador ~ ., data = ttraining, kernel = "linear")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.svm <- no.svm + MC["No", "No"]
    
    modelo <- train.kknn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.knn <- no.knn + MC["No", "No"]
    
    modelo <- naiveBayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.bayes <- no.bayes + MC["No", "No"]
    
    modelo = rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting, type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.arbol <- no.arbol + MC["No", "No"]
    
    modelo <- randomForest(BuenPagador ~ ., data = ttraining, importance = TRUE)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.bosque <- no.bosque + MC["No", "No"]
    
    modelo <- ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.potenciacion <- no.potenciacion + MC["No", "No"]
    
    modelo <- nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
                   decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting[, -6], type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, factor(prediccion, levels = levels(Actual)), exclude = FALSE)
    # Detección de los No Pagadores
    no.red <- no.red + MC["No", "No"]
  }
  deteccion.no.svm[i] <- no.svm
  deteccion.no.knn[i] <- no.knn
  deteccion.no.bayes[i] <- no.bayes
  deteccion.no.arbol[i] <- no.arbol
  deteccion.no.bosque[i] <- no.bosque
  deteccion.no.potenciacion[i] <- no.potenciacion
  deteccion.no.red[i] <- no.red
}

tiempo.no.paralelo <- Sys.time() - tiempo.no.paralelo
```

**Graficamos los resultados**
```{r}
resultados <- data.frame("svm" = deteccion.no.svm,
                         "k_vecinos" = deteccion.no.knn,
                         "bayes" = deteccion.no.bayes,
                         "arboles" = deteccion.no.arbol,
                         "bosques" = deteccion.no.bosque,
                         "potenciacion" = deteccion.no.potenciacion,
                         "redes_nnet" = deteccion.no.red)

matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

**Tiempo de ejecución**
```{r}
tiempo.no.paralelo
```

### Paquete trainR

La manipulación de los datos se puede hacer muy pesada cuando tratamos con `xgboost` y `neuralnet`, pero con `trainR` resulta más fácil.

**Se cargan las librerías**
```{r}
library(caret)
library(trainR)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.svm <- c()
deteccion.no.knn <- c()
deteccion.no.bayes <- c()
deteccion.no.arbol <- c()
deteccion.no.bosque <- c()
deteccion.no.potenciacion <- c()
deteccion.no.red <- c()
deteccion.no.xgboost <- c()
deteccion.no.red.neu <- c()
deteccion.no.glm <- c()

# Medimos tiempo de ejecución
tiempo.no.paralelo <- Sys.time()

# Validación cruzada 5 veces
for (i in 1:cantidad.validacion.cruzada) {
  grupos <- createFolds(1:numero.filas, cantidad.grupos) # Crea los 10 grupos
  no.svm <- 0
  no.knn <- 0
  no.bayes <- 0
  no.arbol <- 0
  no.bosque <- 0
  no.potenciacion <- 0
  no.red <- 0
  no.xg  <- 0
  no.red.neu <- 0
  no.glm <- 0
  
  # Este ciclo es el que hace validación cruzada con 10 grupos
  for (k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- train.svm(BuenPagador ~ ., data = ttraining, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.svm <- no.svm + MC["No", "No"]
    
    modelo <- train.knn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.knn <- no.knn + MC["No", "No"]
    
    modelo <- train.bayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.bayes <- no.bayes + MC["No", "No"]
    
    modelo = train.rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.arbol <- no.arbol + MC["No", "No"]
    
    modelo <- train.randomForest(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.bosque <- no.bosque + MC["No", "No"]
    
    modelo <- train.ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.potenciacion <- no.potenciacion + MC["No", "No"]
    
    modelo <- train.nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
               decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.red <- no.red + MC["No", "No"]
    
    modelo <- train.xgboost(BuenPagador ~ ., data = ttraining, nrounds = 79,
                        print_every_n = 10, maximize = F , eval_metric = "error")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.xg <- no.xg + MC["No", "No"]
    
    modelo <- train.neuralnet(BuenPagador ~., data = ttraining, hidden = c(3, 2,6), 
                          linear.output = FALSE, threshold = 0.5, stepmax = 1e+06)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.red.neu <- no.red.neu + MC["No", "No"]
    
    modelo <- train.glm(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.glm <- no.glm + MC["No", "No"]
  }
  deteccion.no.svm[i] <- no.svm
  deteccion.no.knn[i] <- no.knn
  deteccion.no.bayes[i] <- no.bayes
  deteccion.no.arbol[i] <- no.arbol
  deteccion.no.bosque[i] <- no.bosque
  deteccion.no.potenciacion[i] <- no.potenciacion
  deteccion.no.red[i] <- no.red
  deteccion.no.xgboost[i] <- no.xg
  deteccion.no.red.neu[i] <- no.red.neu
  deteccion.no.glm[i] <- no.glm
}

tiempo.no.paralelo <- Sys.time() - tiempo.no.paralelo
```

**Graficamos los resultados**
```{r}
resultados <- data.frame("svm" = deteccion.no.svm,
                         "k_vecinos" = deteccion.no.knn,
                         "bayes" = deteccion.no.bayes,
                         "arboles" = deteccion.no.arbol,
                         "bosques" = deteccion.no.bosque,
                         "potenciacion" = deteccion.no.potenciacion,
                         "redes_nnet" = deteccion.no.red,
                         "xgboost" = deteccion.no.xgboost,
                         "redes_neuralnet" = no.red.neu, 
                         "regresion_logistica" = deteccion.no.glm)

matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

**Tiempo de ejecución**
```{r}
tiempo.no.paralelo
```


**Otra manera de hacerlo:**
```{r message=FALSE, warning=FALSE, echo=FALSE}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

metodos <- c("svm", "k_vecinos", "bayes", "arboles", "bosques", "potenciacion", 
             "redes_nnet", "xgboost", "redes_neuralnet", "regresion_logistica") # Los nombres para identificarlos

funciones <- list(train.svm, train.knn, train.bayes, train.rpart, train.randomForest, train.ada,
                  train.nnet, train.xgboost, train.neuralnet, train.glm) # Las funciones (en orden con respecto a "metodos")

parametros <- list(list(kernel = "linear", probability = FALSE), 
                   list(kmax = 37), list() , list(), list(),
                   list(iter = 20, nu = 1, type = "discrete"),
                   list(size = 100, MaxNWts = 5000, rang = 0.01, decay = 5e-4, maxit = 45, trace = TRUE),
                   list(nrounds = 79, print_every_n = 10, maximize = FALSE , eval_metric = "error"),
                   list(hidden = c(3, 2,6), linear.output = FALSE, threshold = 0.5, stepmax = 1e+06),
                   list()) # Los parametros de cada modelo (en orden con respecto a "metodos")

resultados <- matrix(0, nrow = cantidad.validacion.cruzada, ncol = 10) # ncol la cantidad de modelos a usar
colnames(resultados) <- metodos
names(funciones) <- metodos
names(parametros) <- metodos

tiempo.no.paralelo <- Sys.time()

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    for(metodo in metodos) { # Ejecutamos cada metodo
      .fun <- funciones[[metodo]] # Obtengo la funcion que quiero usar
      params <- parametros[[metodo]] # Obtengo los parametros que quiero usar
      # do.call llama a una funcion con los parametros que le pasemos como lista
      # substitute nos permite poner el nombre de la variable "ttraining" en lugar del valor
      modelo <- do.call(.fun, c(BuenPagador ~ ., data = substitute(ttraining), params))
      prediccion <- predict(modelo, ttesting)
      MC <- confusion.matrix(ttesting, prediccion)
      resultados[i, metodo] <- resultados[i, metodo] + MC["No","No"] # Detección de los NO Pagadores
    }
    
  }
}

tiempo.no.paralelo <- Sys.time() - tiempo.no.paralelo
```

**Graficamos los resultados**
```{r}
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=.05, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

**Tiempo de ejecución**
```{r}
tiempo.no.paralelo
```

##

## Versión Paralela

## {.tabset}

### Paquetes

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(caret)
  library(e1071)
  library(kknn)
  library(class)
  library(rpart)
  library(randomForest)
  library(ada)
  library(nnet)
  library(dplyr)
  
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.svm <- 0
  no.knn <- 0
  no.bayes <- 0
  no.arbol <- 0
  no.bosque <- 0
  no.potenciacion <- 0
  no.red <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- svm(BuenPagador ~ ., data = ttraining, kernel = "linear")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.svm <- no.svm + MC["No", "No"]
    
    modelo <- train.kknn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.knn <- no.knn + MC["No", "No"]
    
    modelo <- naiveBayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.bayes <- no.bayes + MC["No", "No"]
    
    modelo = rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting, type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.arbol <- no.arbol + MC["No", "No"]
    
    modelo <- randomForest(BuenPagador ~ ., data = ttraining, importance = TRUE)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.bosque <- no.bosque + MC["No", "No"]
    
    modelo <- ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.potenciacion <- no.potenciacion + MC["No", "No"]
    
    modelo <- nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
                   decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting[, -6], type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, factor(prediccion, levels = levels(Actual)), exclude = FALSE)
    # Detección de los No Pagadores
    no.red <- no.red + MC["No", "No"]
  }
  
  return(list("svm"     = no.svm, 
              "knn"     = no.knn, 
              "bayes"   = no.bayes, 
              "arboles" = no.arbol,
              "bosques" = no.bosque,
              "potenciacion" = no.potenciacion,
              "redes_nnet" = no.red))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

### trainR

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(caret)
  library(trainR)
  
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.svm <- 0
  no.knn <- 0
  no.bayes <- 0
  no.arbol <- 0
  no.bosque <- 0
  no.potenciacion <- 0
  no.red <- 0
  no.xg  <- 0
  no.red.neu <- 0
  no.glm <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- train.svm(BuenPagador ~ ., data = ttraining, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.svm <- no.svm + MC["No", "No"]
    
    modelo <- train.knn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.knn <- no.knn + MC["No", "No"]
    
    modelo <- train.bayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.bayes <- no.bayes + MC["No", "No"]
    
    modelo = train.rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.arbol <- no.arbol + MC["No", "No"]
    
    modelo <- train.randomForest(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.bosque <- no.bosque + MC["No", "No"]
    
    modelo <- train.ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.potenciacion <- no.potenciacion + MC["No", "No"]
    
    modelo <- train.nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
               decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.red <- no.red + MC["No", "No"]
    
    modelo <- train.xgboost(BuenPagador ~ ., data = ttraining, nrounds = 79,
                        print_every_n = 10, maximize = F , eval_metric = "error")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.xg <- no.xg + MC["No", "No"]
    
    modelo <- train.neuralnet(BuenPagador ~., data = ttraining, hidden = c(3, 2,6), 
                          linear.output = FALSE, threshold = 0.5, stepmax = 1e+06)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.red.neu <- no.red.neu + MC["No", "No"]
    
    modelo <- train.glm(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.glm <- no.glm + MC["No", "No"]
  }
  
  return(list("svm"     = no.svm, 
              "knn"     = no.knn, 
              "bayes"   = no.bayes, 
              "arboles" = no.arbol,
              "bosques" = no.bosque,
              "potenciacion" = no.potenciacion,
              "redes_nnet" = no.red,
              "xgboost" = no.xg,
              "redes_neuralnet" = no.red.neu,
              "regresion_logistica" = no.glm))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Graficamos los resultados**
```{r}
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Detección del NO pagador", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

##

## Veamos el error (Versión Paralela)


## {.tabset}

### Paquetes

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(caret)
  library(e1071)
  library(kknn)
  library(class)
  library(rpart)
  library(randomForest)
  library(ada)
  library(nnet)
  library(dplyr)
  
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  error.svm <- 0
  error.knn <- 0
  error.bayes <- 0
  error.arbol <- 0
  error.bosque <- 0
  error.potenciacion <- 0
  error.red <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- svm(BuenPagador ~ ., data = ttraining, kernel = "linear")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    error.svm <- error.svm + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.kknn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    error.knn <- error.knn + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- naiveBayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    error.bayes <- error.bayes + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo = rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting, type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    error.arbol <- error.arbol + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- randomForest(BuenPagador ~ ., data = ttraining, importance = TRUE)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    error.bosque <- error.bosque + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    error.potenciacion <- error.potenciacion + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
                   decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting[, -6], type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, factor(prediccion, levels = levels(Actual)), exclude = FALSE)
    # Detección de los No Pagadores
    error.red <- error.red + (1 - (sum(diag(MC)) / sum(MC))) * 100
  }
  
  return(list("svm"     = error.svm / cantidad.grupos, 
              "knn"     = error.knn / cantidad.grupos, 
              "bayes"   = error.bayes / cantidad.grupos, 
              "arboles" = error.arbol / cantidad.grupos,
              "bosques" = error.bosque / cantidad.grupos,
              "potenciacion" = error.potenciacion / cantidad.grupos,
              "redes_nnet" = error.red / cantidad.grupos))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel linear**
```{r}
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Comparación del Error Global", 
        xlab = "Número de iteración",
        ylab = "Error Global",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

### trainR

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(caret)
  library(trainR)
  
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  error.svm <- 0
  error.knn <- 0
  error.bayes <- 0
  error.arbol <- 0
  error.bosque <- 0
  error.potenciacion <- 0
  error.red <- 0
  error.xg  <- 0
  error.red.neu <- 0
  error.glm <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- train.svm(BuenPagador ~ ., data = ttraining, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    error.svm <- error.svm + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.knn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    error.knn <- error.knn + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.bayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    error.bayes <- error.bayes + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo = train.rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    error.arbol <- error.arbol + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.randomForest(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    error.bosque <- error.bosque + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    error.potenciacion <- error.potenciacion + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
               decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    error.red <- error.red + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.xgboost(BuenPagador ~ ., data = ttraining, nrounds = 79,
                        print_every_n = 10, maximize = F , eval_metric = "error")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    error.xg <- error.xg + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.neuralnet(BuenPagador ~., data = ttraining, hidden = c(3, 2,6), 
                          linear.output = FALSE, threshold = 0.5, stepmax = 1e+06)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    error.red.neu <- error.red.neu + (1 - (sum(diag(MC)) / sum(MC))) * 100
    
    modelo <- train.glm(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    error.glm <- error.glm + (1 - (sum(diag(MC)) / sum(MC))) * 100
  }
  
  return(list("svm"     = error.svm, 
              "knn"     = error.knn, 
              "bayes"   = error.bayes, 
              "arboles" = error.arbol,
              "bosques" = error.bosque,
              "potenciacion" = error.potenciacion,
              "redes_nnet" = error.red,
              "xgboost" = error.xg,
              "redes_neuralnet" = error.red.neu,
              "regresion_logistica" = error.glm))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Graficamos los resultados**
```{r}
matplot(resultados, type="b", lty = 1, lwd = 1, pch = 1:ncol(resultados),
        main = "Comparación del Error Global", 
        xlab = "Número de iteración",
        ylab = "Error Global",
        col = rainbow(ncol(resultados)))
legend('bottomright', inset=0, legend = colnames(resultados), 
       pch=1:ncol(resultados), horiz = TRUE, col = rainbow(ncol(resultados)))
```

##

En problemas reales la validación cruzada solo se ejecuta una vez y con lo modelos debidamente calibrados.

## {.tabset}

### Paquetes

**Se cargan las librerías**
```{r}
library(snow)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.grupos <- 10
numero.filas <- nrow(datos)
grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
clusterExport(clp, "grupos")

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.grupos, function(k) {
  library(caret)
  library(e1071)
  library(kknn)
  library(class)
  library(rpart)
  library(randomForest)
  library(ada)
  library(nnet)
  library(dplyr)

  error.svm <- 0
  error.knn <- 0
  error.bayes <- 0
  error.arbol <- 0
  error.bosque <- 0
  error.potenciacion <- 0
  error.red <- 0
  
  muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
  ttesting <- datos[muestra, ]
  ttraining <- datos[-muestra, ]
  
  modelo <- svm(BuenPagador ~ ., data = ttraining, kernel = "linear")
  prediccion <- predict(modelo, ttesting)
  Actual <- ttesting[, 6]
  MC <- table(Actual, prediccion)
  # Detección de los No Pagadores
  error.svm <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo <- train.kknn(BuenPagador ~ ., data = ttraining, kmax = 37)
  prediccion <- predict(modelo, ttesting[, -6])
  Actual <- ttesting[, 6]
  MC <- table(Actual, prediccion)
  # Detección de los No Pagadores
  error.knn <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo <- naiveBayes(BuenPagador ~ ., data = ttraining)
  prediccion <- predict(modelo, ttesting[, -6])
  Actual <- ttesting[, 6]
  MC <- table(Actual, prediccion)
  # Detección de los No Pagadores
  error.bayes <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo = rpart(BuenPagador ~ ., data = ttraining)
  prediccion <- predict(modelo, ttesting, type = "class")
  Actual <- ttesting[, 6]
  MC <- table(Actual, prediccion)
  # Detección de los No Pagadores
  error.arbol <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo <- randomForest(BuenPagador ~ ., data = ttraining, importance = TRUE)
  prediccion <- predict(modelo, ttesting[, -6])
  Actual <- ttesting[, 6]
  MC <- table(Actual, prediccion)
  # Detección de los No Pagadores
  error.bosque <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo <- ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
  prediccion <- predict(modelo, ttesting[, -6])
  Actual <- ttesting[, 6]
  MC <- table(Actual, prediccion)
  # Detección de los No Pagadores
  error.potenciacion <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo <- nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
                 decay = 5e-4, maxit = 45, trace = TRUE)
  prediccion <- predict(modelo, ttesting[, -6], type = "class")
  Actual <- ttesting[, 6]
  MC <- table(Actual, factor(prediccion, levels = levels(Actual)), exclude = FALSE)
  # Detección de los No Pagadores
  error.red <- (1 - (sum(diag(MC)) / sum(MC))) * 100

  return(list("svm"     = error.svm, 
              "knn"     = error.knn , 
              "bayes"   = error.bayes, 
              "arboles" = error.arbol,
              "bosques" = error.bosque,
              "potenciacion" = error.potenciacion,
              "redes_nnet" = error.red))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
nombres <- names(resultados[[1]])
resultados <- lapply(resultados, as.numeric)
resultados <- do.call(rbind, resultados)
colnames(resultados) <- nombres
resultados
```

**Por lo tanto el resultado para cada modelo sería:**
```{r}
resultados <- colSums(resultados) / nrow(resultados)
resultados
```

### trainR

**Se cargan las librerías**
```{r}
library(snow)
library(caret)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")
cantidad.grupos <- 10
numero.filas <- nrow(datos)
grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
clusterExport(clp, "grupos")

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.grupos, function(k) {
  library(caret)
  library(trainR)

  error.svm <- 0
  error.knn <- 0
  error.bayes <- 0
  error.arbol <- 0
  error.bosque <- 0
  error.potenciacion <- 0
  error.red <- 0
  error.xg  <- 0
  error.red.neu <- 0
  error.glm <- 0
  
  muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
  ttesting <- datos[muestra, ]
  ttraining <- datos[-muestra, ]
  
  modelo <- train.svm(BuenPagador ~ ., data = ttraining, kernel = "linear", probability = FALSE)
  prediccion <- predict(modelo, ttesting)
  MC <- confusion.matrix(ttesting, prediccion)
  # Detección de los No Pagadores
  error.svm <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo <- train.knn(BuenPagador ~ ., data = ttraining, kmax = 37)
  prediccion <- predict(modelo, ttesting)
  MC <- confusion.matrix(ttesting, prediccion)
  # Detección de los No Pagadores
  error.knn <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo <- train.bayes(BuenPagador ~ ., data = ttraining)
  prediccion <- predict(modelo, ttesting)
  MC <- confusion.matrix(ttesting, prediccion)
  # Detección de los No Pagadores
  error.bayes <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo = train.rpart(BuenPagador ~ ., data = ttraining)
  prediccion <- predict(modelo, ttesting)
  MC <- confusion.matrix(ttesting, prediccion)
  # Detección de los No Pagadores
  error.arbol <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo <- train.randomForest(BuenPagador ~ ., data = ttraining)
  prediccion <- predict(modelo, ttesting)
  MC <- confusion.matrix(ttesting, prediccion)
  # Detección de los No Pagadores
  error.bosque <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo <- train.ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
  prediccion <- predict(modelo, ttesting)
  MC <- confusion.matrix(ttesting, prediccion)
  # Detección de los No Pagadores
  error.potenciacion <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  modelo <- train.ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
  prediccion <- predict(modelo, ttesting)
  MC <- confusion.matrix(ttesting, prediccion)
  # Detección de los No Pagadores
  error.red <- (1 - (sum(diag(MC)) / sum(MC))) * 100

  modelo <- train.xgboost(BuenPagador ~ ., data = ttraining, nrounds = 79,
                      print_every_n = 10, maximize = F , eval_metric = "error")
  prediccion <- predict(modelo, ttesting)
  MC <- confusion.matrix(ttesting, prediccion)
  # Detección de los No Pagadores
  error.xg <- (1 - (sum(diag(MC)) / sum(MC))) * 100

  modelo <- train.neuralnet(BuenPagador ~., data = ttraining, hidden = c(3, 2,6),
                        linear.output = FALSE, threshold = 0.5, stepmax = 1e+06)
  prediccion <- predict(modelo, ttesting)
  MC <- confusion.matrix(ttesting, prediccion)
  # Detección de los No Pagadores
  error.red.neu <- (1 - (sum(diag(MC)) / sum(MC))) * 100

  modelo <- train.glm(BuenPagador ~ ., data = ttraining)
  prediccion <- predict(modelo, ttesting)
  MC <- confusion.matrix(ttesting, prediccion)
  # Detección de los No Pagadores
  error.glm <- (1 - (sum(diag(MC)) / sum(MC))) * 100
  
  return(list("svm"     = error.svm, 
              "knn"     = error.knn, 
              "bayes"   = error.bayes, 
              "arboles" = error.arbol,
              "bosques" = error.bosque,
              "potenciacion" = error.potenciacion,
              "redes_nnet" = error.red,
              "xgboost" = error.xg,
              "redes_neuralnet" = error.red.neu,
              "regresion_logistica" = error.glm))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
nombres <- names(resultados[[1]])
resultados <- lapply(resultados, as.numeric)
resultados <- do.call(rbind, resultados)
colnames(resultados) <- nombres
resultados
```

**Por lo tanto el resultado para cada modelo sería:**
```{r}
resultados <- colSums(resultados) / nrow(resultados)
resultados
```

##


---
output:
  html_document: 
    df_print: paged
    highlight: haddock
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = NA, fig.width=13, fig.height = 10)
```

![](logo.jpg)

# Calibración y Selección de Modelos en Paralelo

## Calibrando el método "Máquinas Vectoriales de Soporte" para los datos de Scoring de Crédito

## Versión NO Paralela

#### Para esto usaremos archivo "MuestraCredito5000V2.csv""

**En el caso del Scoring de Crédito lo que más interesa en detectar a los NO pagadores, por esa razón ejecutaremos 5 veces la validación cruzada usando 10 grupos. En cada paso de la valización cruzada vamos sumando los no pagadores detectados, luego para cada ejecución de la valizadación cruzada almacenamos la detección de los no pagadores en una entrada del vector respectivo al método para luego hacer un gráfico comparativo.**

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

## {.tabset}

### Paquete e1071

**Se cargan las librerías**
```{r}
library(caret)
library(e1071)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.radial <- c()
deteccion.no.linear <- c()
deteccion.no.polynomial <- c()
deteccion.no.sigmoid <- c()

tiempo.usual <- Sys.time() 

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    #Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  deteccion.no.radial[i] <- no.radial
  deteccion.no.linear[i] <- no.linear
  deteccion.no.polynomial[i] <- no.polynomial
  deteccion.no.sigmoid[i] <- no.sigmoid
}

tiempo.usual <- Sys.time() -  tiempo.usual
```

```{r}
tiempo.usual
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel Radial**

```{r}
plot(deteccion.no.radial, col = "magenta", type = "b", 
     ylim = c(min(deteccion.no.radial,
                  deteccion.no.linear, deteccion.no.polynomial, 
                  deteccion.no.sigmoid), max(deteccion.no.radial,
                                             deteccion.no.linear, deteccion.no.polynomial, 
                                             deteccion.no.sigmoid) + 150), # Cuidado con el + 150, es para ampliar el eje "y"
     main = "Detección del NO pagador en SVM", 
     xlab = "Número de iteración",
     ylab = "Cantidad de NO pagadores detectados")
points(deteccion.no.linear, col = "blue", type = "b")
points(deteccion.no.polynomial, col = "red", type = "b")
points(deteccion.no.sigmoid, col = "green", type = "b")
legend("topright", legend = c("Radial", "Linear", "Polynomial", "Sigmoid"),
       col = c("magenta", "blue", "red", "green"), lty = 1, lwd = 1)
```

### Paquete trainR

**Se cargan las librerías**
```{r}
library(caret)
library(trainR)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.radial <- c()
deteccion.no.linear <- c()
deteccion.no.polynomial <- c()
deteccion.no.sigmoid <- c()

tiempo.usual <- Sys.time()

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  deteccion.no.radial[i] <- no.radial
  deteccion.no.linear[i] <- no.linear
  deteccion.no.polynomial[i] <- no.polynomial
  deteccion.no.sigmoid[i] <- no.sigmoid
}

tiempo.usual <- Sys.time() - tiempo.usual
```

```{r}
tiempo.usual
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel Radial**

```{r}
plot(deteccion.no.radial, col = "magenta", type = "b", 
     ylim = c(min(deteccion.no.radial,
                  deteccion.no.linear, deteccion.no.polynomial, 
                  deteccion.no.sigmoid), max(deteccion.no.radial,
                                             deteccion.no.linear, deteccion.no.polynomial, 
                                             deteccion.no.sigmoid) + 150), # Cuidado con el + 150, es para ampliar el eje "y"
     main = "Detección del NO pagador en SVM", 
     xlab = "Número de iteración",
     ylab = "Cantidad de NO pagadores detectados")
points(deteccion.no.linear, col = "blue", type = "b")
points(deteccion.no.polynomial, col = "red", type = "b")
points(deteccion.no.sigmoid, col = "green", type = "b")
legend("topright", legend = c("Radial", "Linear", "Polynomial", "Sigmoid"),
       col = c("magenta", "blue", "red", "green"), lty = 1, lwd = 1)
```

**Otra forma de hacerlo es:**

**Se cargan las librerías**
```{r}
library(caret)
library(trainR)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10
kernels <- c("radial", "linear", "polynomial", "sigmoid")

resultados <- matrix(0, nrow = cantidad.validacion.cruzada, ncol = 4) # ncol la cantidad de modelos a usar
colnames(resultados) <- kernels # opcional

tiempo.usual <- Sys.time()

for(i in seq_len(cantidad.validacion.cruzada)){
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    for(kernel in kernels) {
      modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = kernel, probability = FALSE)
      prediccion <- predict(modelo, ttesting)
      MC <- confusion.matrix(ttesting, prediccion)
      resultados[i, kernel] <- resultados[i, kernel] + MC["No","No"] # Detección de los NO Pagadores
    }
  }
}

tiempo.usual <- Sys.time() - tiempo.usual

```

```{r}
tiempo.usual
```

**El resultado se encuentra en cada columna de `resultados`**
```{r}
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel Radial**
```{r}
matplot(resultados, type="b",lty = 1, lwd = 1,
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados")
legend('bottomright', inset=.05, legend = colnames(resultados), 
       pch=1, horiz = TRUE, col = 1:4)
```

##

## Versión Paralela

## {.tabset}

### Paquete e1071

**Se cargan las librerías**
```{r}
library(e1071)
library(caret)
library(snow)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")

cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(e1071)
  library(caret)
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  return(list("radial"     = no.radial, 
              "linear"     = no.linear, 
              "polynomial" = no.polynomial, 
              "sigmoid"    = no.sigmoid))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel Radial**
```{r}
matplot(resultados, type="b",lty = 1, lwd = 1,
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados")
legend('bottomright', inset=.05, legend = colnames(resultados), 
       pch=1, horiz = TRUE, col = 1:4)
```

### Paquete trainR

**Se cargan las librerías**
```{r}
library(trainR)
library(caret)
library(snow)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

**Constructor del cluster**
```{r}
clusterExport(clp, "datos")

cantidad.validacion.cruzada <- 5

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(trainR)
  library(caret)
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  
  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  no.radial <- 0
  no.linear <- 0
  no.polynomial <- 0
  no.sigmoid <- 0
  
  # Este ciclo es el que hace 'cross-validation' (validación cruzada) con 10
  # grupos (Folds)
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "radial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.radial <- no.radial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "linear", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.linear <- no.linear + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "polynomial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.polynomial <- no.polynomial + MC["No", "No"]
    
    modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = "sigmoid", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los NO Pagadores
    no.sigmoid <- no.sigmoid + MC["No", "No"]
  }
  
  return(list("radial"     = no.radial, 
              "linear"     = no.linear, 
              "polynomial" = no.polynomial, 
              "sigmoid"    = no.sigmoid))
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de listas, debemos de convertirlo para manejarlo mejor**
```{r}
resultados <- do.call(rbind, resultados)
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel Radial**
```{r}
matplot(resultados, type="b",lty = 1, lwd = 1,
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados")
legend('bottomright', inset=.05, legend = colnames(resultados), 
       pch=1, horiz = TRUE, col = 1:4)
```

**Otra forma de hacerlo es:**

**Proceso Paralelo**
```{r}
clp <- makeCluster(5, type = "SOCK")
```

```{r}
clusterExport(clp, "datos")
cantidad.validacion.cruzada <- 5
clusterExport(clp, "cantidad.validacion.cruzada")

tiempo.paralelo <- Sys.time()

resultados <- clusterApply(clp, 1:cantidad.validacion.cruzada, function(indice) {
  library(trainR)
  library(caret)
  numero.filas <- nrow(datos)
  cantidad.grupos <- 10
  kernels <- c("radial", "linear", "polynomial", "sigmoid")
  
  resultados <- matrix(0, nrow = cantidad.validacion.cruzada, ncol = 4) # ncol la cantidad de modelos a usar
  colnames(resultados) <- kernels # opcional

  grupos  <- createFolds(1:numero.filas, cantidad.grupos)  # Crea los 10 grupos
  
  for(k in 1:cantidad.grupos) {
    muestra <- grupos[[k]]  # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    taprendizaje <- datos[-muestra, ]
    
    for(kernel in kernels) {
      modelo <- train.svm(BuenPagador ~ ., data = taprendizaje, kernel = kernel, probability = FALSE)
      prediccion <- predict(modelo, ttesting)
      MC <- confusion.matrix(ttesting, prediccion)
      resultados[indice, kernel] <- resultados[indice, kernel] + MC["No","No"] # Detección de los NO Pagadores
    }
  }
  return(resultados)
})

tiempo.paralelo <- Sys.time() - tiempo.paralelo

stopCluster(clp)
```

```{r}
tiempo.paralelo
```

**El resultado es una lista de matrices, debemos de convertirlo para manejarlo mejor**

```{r}
resultados <- Reduce("+", resultados)
resultados
```

**Como se puede verificar en el gráfico el mejor resultado se obtiene usando un Kernel Radial**
```{r}
matplot(resultados, type="b",lty = 1, lwd = 1,
        main = "Detección del NO pagador en SVM", 
        xlab = "Número de iteración",
        ylab = "Cantidad de NO pagadores detectados")
legend('bottomright', inset=.05, legend = colnames(resultados), 
       pch=1, horiz = TRUE, col = 1:4)
```

##


# Seleccionando el mejor método para los datos de Scoring de Crédito

## Versión NO Paralela

## {.tabset}

### Paquetes

**Se cargan las librerías**
```{r}
library(caret)
library(e1071)
library(kknn)
library(class)
library(rpart)
library(randomForest)
library(ada)
library(nnet)
library(magrittr)
library(dplyr)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

```{r}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.svm <- c()
deteccion.no.knn <- c()
deteccion.no.bayes <- c()
deteccion.no.arbol <- c()
deteccion.no.bosque <- c()
deteccion.no.potenciacion <- c()
deteccion.no.red <- c()

# Medimos tiempo de ejecución
tiempo.no.paralelo <- Sys.time()

# Validación cruzada 5 veces
for (i in 1:cantidad.validacion.cruzada) {
  grupos <- createFolds(1:numero.filas, cantidad.grupos) # Crea los 10 grupos
  no.svm <- 0
  no.knn <- 0
  no.bayes <- 0
  no.arbol <- 0
  no.bosque <- 0
  no.potenciacion <- 0
  no.red <- 0
  
  # Este ciclo es el que hace validación cruzada con 10 grupos
  for (k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- svm(BuenPagador ~ ., data = ttraining, kernel = "radial")
    prediccion <- predict(modelo, ttesting)
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.svm <- no.svm + MC["No", "No"]
    
    modelo <- train.kknn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.knn <- no.knn + MC["No", "No"]
    
    modelo <- naiveBayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.bayes <- no.bayes + MC["No", "No"]
    
    modelo = rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting, type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.arbol <- no.arbol + MC["No", "No"]
    
    modelo <- randomForest(BuenPagador ~ ., data = ttraining, importance = TRUE)
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.bosque <- no.bosque + MC["No", "No"]
    
    modelo <- ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting[, -6])
    Actual <- ttesting[, 6]
    MC <- table(Actual, prediccion)
    # Detección de los No Pagadores
    no.potenciacion <- no.potenciacion + MC["No", "No"]
    
    modelo <- nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
                   decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting[, -6], type = "class")
    Actual <- ttesting[, 6]
    MC <- table(Actual, factor(prediccion, levels = levels(Actual)), exclude = FALSE)
    # Detección de los No Pagadores
    no.red <- no.red + MC["No", "No"]
  }
  deteccion.no.svm[i] <- no.svm
  deteccion.no.knn[i] <- no.knn
  deteccion.no.bayes[i] <- no.bayes
  deteccion.no.arbol[i] <- no.arbol
  deteccion.no.bosque[i] <- no.bosque
  deteccion.no.potenciacion[i] <- no.potenciacion
  deteccion.no.red[i] <- no.red
}

tiempo.no.paralelo <- Sys.time() - tiempo.no.paralelo
```

**Graficamos los resultados**
```{r}
plot(deteccion.no.svm, col = "magenta", type = "b", ylim = c(min(deteccion.no.svm,deteccion.no.knn,deteccion.no.bayes,deteccion.no.arbol,deteccion.no.bosque,deteccion.no.potenciacion,deteccion.no.red), max(deteccion.no.svm, deteccion.no.knn, deteccion.no.bayes, deteccion.no.arbol,deteccion.no.bosque,deteccion.no.potenciacion,deteccion.no.red)), xlim = c(1, 5.5), main = "Detección del No pagador", xlab = "Número de iteración", ylab = "Cantidad de No Pagadores detectados")
points(deteccion.no.knn, col = "blue", type = "b")
points(deteccion.no.arbol, col = "red", type = "b")
points(deteccion.no.bosque, col = "green", type = "b")
points(deteccion.no.bayes, col = "lightpink2", type = "b")
points(deteccion.no.potenciacion, col = "orange3", type = "b")
points(deteccion.no.red, col = "rosybrown4", type = "b")
legend("topright", legend = c("SVM","KNN","Árbol","Bosque","Bayes","Potenciación","Red Neuronal"), col = c("magenta","blue","red","green","lightpink2","orange3","rosybrown4"), lty = 1, lwd = 2)
```

**Tiempo de ejecución**
```{r}
tiempo.no.paralelo
```

### Paquete trainR

La manipulación de los datos se puede hacer muy pesada cuando tratamos con `xgboost` y `neuralnet`, pero con `trainR` resulta más fácil.

**Se cargan las librerías**
```{r}
library(caret)
library(trainR)
```

```{r}
setwd("~/Desktop/Datos/")
datos <- read.csv("MuestraCredito5000V2.csv", sep = ";", header=T)

# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
numero.filas <- nrow(datos)
cantidad.validacion.cruzada <- 5
cantidad.grupos <- 10

deteccion.no.svm <- c()
deteccion.no.knn <- c()
deteccion.no.bayes <- c()
deteccion.no.arbol <- c()
deteccion.no.bosque <- c()
deteccion.no.potenciacion <- c()
deteccion.no.red <- c()
deteccion.no.xgboost <- c()
deteccion.no.red.neu <- c()
deteccion.no.glm <- c()

# Medimos tiempo de ejecución
tiempo.no.paralelo <- Sys.time()

# Validación cruzada 5 veces
for (i in 1:cantidad.validacion.cruzada) {
  grupos <- createFolds(1:numero.filas, cantidad.grupos) # Crea los 10 grupos
  no.svm <- 0
  no.knn <- 0
  no.bayes <- 0
  no.arbol <- 0
  no.bosque <- 0
  no.potenciacion <- 0
  no.red <- 0
  no.xg  <- 0
  no.red.neu <- 0
  no.glm <- 0
  
  # Este ciclo es el que hace validación cruzada con 10 grupos
  for (k in 1:cantidad.grupos) {
    muestra <- grupos[[k]] # Por ser una lista requiere de doble paréntesis
    ttesting <- datos[muestra, ]
    ttraining <- datos[-muestra, ]
    
    modelo <- train.svm(BuenPagador ~ ., data = ttraining, kernel = "radial", probability = FALSE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.svm <- no.svm + MC["No", "No"]
    
    modelo <- train.knn(BuenPagador ~ ., data = ttraining, kmax = 37)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.knn <- no.knn + MC["No", "No"]
    
    modelo <- train.bayes(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.bayes <- no.bayes + MC["No", "No"]
    
    modelo = train.rpart(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.arbol <- no.arbol + MC["No", "No"]
    
    modelo <- train.randomForest(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.bosque <- no.bosque + MC["No", "No"]
    
    modelo <- train.ada(BuenPagador ~ ., data = ttraining, iter = 20, nu = 1, type = "discrete")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.potenciacion <- no.potenciacion + MC["No", "No"]
    
    modelo <- train.nnet(BuenPagador ~ ., data = ttraining, size = 100, MaxNWts = 5000, rang = 0.01, 
               decay = 5e-4, maxit = 45, trace = TRUE)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.red <- no.red + MC["No", "No"]
    
    modelo <- train.xgboost(BuenPagador ~ ., data = ttraining, nrounds = 79,
                        print_every_n = 10, maximize = F , eval_metric = "error")
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.xg <- no.xg + MC["No", "No"]
    
    modelo <- train.neuralnet(BuenPagador ~., data = ttraining, hidden = c(3, 2,6), 
                          linear.output = FALSE, threshold = 0.5, stepmax = 1e+06)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.red.neu <- no.red.neu + MC["No", "No"]
    
    modelo <- train.glm(BuenPagador ~ ., data = ttraining)
    prediccion <- predict(modelo, ttesting)
    MC <- confusion.matrix(ttesting, prediccion)
    # Detección de los No Pagadores
    no.glm <- no.glm + MC["No", "No"]
  }
  deteccion.no.svm[i] <- no.svm
  deteccion.no.knn[i] <- no.knn
  deteccion.no.bayes[i] <- no.bayes
  deteccion.no.arbol[i] <- no.arbol
  deteccion.no.bosque[i] <- no.bosque
  deteccion.no.potenciacion[i] <- no.potenciacion
  deteccion.no.red[i] <- no.red
  deteccion.no.xgboost[i] <- no.xg
  deteccion.no.red.neu[i] <- no.red.neu
  deteccion.no.glm[i] <- no.glm
}

tiempo.no.paralelo <- Sys.time() - tiempo.no.paralelo
```


```{r}
, echo = FALSE, warning=FALSE, message=FALSE }
```


---
output:
  html_document: 
    df_print: paged
    highlight: haddock
    theme: cerulean
---

![](logo.jpg)

Métodos de Predictivos (Clasificación o Aprendizaje-Supervisado)

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = NA, fig.width=15, fig.height=12)
# options(encoding = "CP1252")
```

# Índices de Calidad del Modelo y Funciones Auxiliares


**Se necesita cargar las siguientes librerías**
```{r}
library(tidyverse)
library(glue)
library(scales)
```

**Muestra la distribución de la variable a predecir**
```{r}
equilibrio.variable.predecir<-function(datos,variable.predecir,ylab="Cantidad de individuos",xlab = "", 
                                       main=paste("Distribución de la variable",variable.predecir), 
                                       col = NA) {
  gg_color <- function (n) {
     hues <- seq(15, 375, length = n + 1)
     hcl(h = hues, l = 65, c = 100)[1:n]
  }
  if(missing(variable.predecir) | !(variable.predecir %in% colnames(datos))){
    stop("variable.predecir tiene que ser ingresada y ser un nombre de columna", call. = FALSE )
  }
  if(is.character(datos[,variable.predecir]) | is.factor(datos[,variable.predecir])){
    if(length(col) == 0 || is.na(col)){
      col <- gg_color(length(unique(datos[,variable.predecir])))
    }else{
      col <- rep(col,length(unique(datos[,variable.predecir])))
    }
    ggplot(data = datos, mapping = aes_string(x = variable.predecir, fill = variable.predecir)) +
      geom_bar() +
      scale_fill_manual(values = col, name = variable.predecir) +
      labs(x = xlab, y = ylab, title = main) +
      theme_minimal() +
      theme(legend.position = "bottom")
  }else{
    stop("La variable a predecir tienen que ser de tipo factor o character", call. = FALSE )
  }
}
```

**Muestra la distribución de una variable numérica según la variable a predecir**
```{r}
poder.predictivo.numerica<-function(datos,variable.predecir,variable.comparar,ylab="",xlab="", 
                                    main=paste("Densidad de la variable",variable.comparar,'según',variable.predecir),
                                    col=NA){
  gg_color <- function (n) {
     hues <- seq(15, 375, length = n + 1)
     hcl(h = hues, l = 65, c = 100)[1:n]
  }
  if(missing(variable.predecir) | !(variable.predecir %in% colnames(datos))){
    stop("variable.predecir tiene que ser ingresada y ser un nombre de columna", call. = FALSE )
  }
  if(missing(variable.comparar) | !(variable.comparar %in% colnames(datos)) | !is.numeric(datos[,variable.comparar])){
    stop("variable.comparar tiene que ser ingresada y ser un nombre de columna numérica", call. = FALSE )
  }
  
  if(is.character(datos[,variable.predecir]) | is.factor(datos[,variable.predecir])){
    if(length(col) == 0 || is.na(col)){
      col <- gg_color(length(unique(datos[,variable.predecir])))
    }else{
      col <- rep(col,length(unique(datos[,variable.predecir])))
    }
    
    ggplot(data = datos, aes_string(variable.comparar, fill = variable.predecir)) +
      geom_density(alpha = .7, color = NA) +
      scale_fill_manual(values = col) +
      labs(title = main , y = ylab, x = xlab ,fill = variable.predecir) +
      theme_minimal() +
      theme(legend.position = 'bottom',
            legend.title = element_blank(),
            text = element_text(size = 15))
    
  }else{
    stop("La variable a predecir tienen que ser de tipo factor o character", call. = FALSE )
  }
}
```

**Muestra la distribución de una variable categórica según la variable a predecir**
```{r}
poder.predictivo.categorica<-function(datos,variable.predecir,variable.comparar,ylab="",xlab="", 
                                      main=paste("Densidad de la variable",variable.comparar,'según',variable.predecir),
                                      col=NA){
  gg_color <- function (n) {
     hues <- seq(15, 375, length = n + 1)
     hcl(h = hues, l = 65, c = 100)[1:n]
  }
  if(missing(variable.predecir) | !(variable.predecir %in% colnames(datos))){
    stop("variable.predecir tiene que ser ingresada y ser un nombre de columna", call. = FALSE )
  }
  if(missing(variable.comparar) | !(variable.comparar %in% colnames(datos)) | 
     !(is.factor(datos[,variable.comparar]) | is.character(datos[,variable.comparar])) ){
    stop("variable.comparar tiene que ser ingresada y ser un nombre de columna categórica", call. = FALSE )
  }
  
  if(is.character(datos[,variable.predecir]) | is.factor(datos[,variable.predecir])){
    if(length(col) == 0 || is.na(col)){
      col <- gg_color(length(unique(datos[,variable.predecir])))
    }else{
      col <- rep(col,length(unique(datos[,variable.predecir])))
    }
    
    datos2 <- datos %>%
      dplyr::group_by_(variable.comparar, variable.predecir) %>%
      dplyr::summarise(count = n())
    
    if(variable.comparar != variable.predecir){
      datos2 <-   datos2 %>% dplyr::group_by_(variable.comparar)
    }
    datos2 <- datos2 %>% dplyr::mutate(prop = round(count/sum(count),4))
  
    ggplot(data = datos2, mapping = aes_string(x = variable.comparar, y = "prop", fill = variable.predecir)) +
      geom_col(position = "fill") +
      geom_text(aes(label = glue("{percent(prop)} ({count})")), position = position_stack(vjust = .5), color = "white") +
      scale_y_continuous(label = percent) +
      labs(y =  xlab, x  = ylab, title = main) +
      scale_fill_manual(values = col, name = variable.predecir) +
      theme(legend.position = "bottom")+
      coord_flip()
    
  }else{
    stop("La variable a predecir tienen que ser de tipo factor o character", call. = FALSE )
  }
}
```

**Índices para matrices NxN**
```{r}
indices.general <- function(MC) {
  precision.global <- sum(diag(MC))/sum(MC)
  error.global <- 1 - precision.global
  precision.categoria <- diag(MC)/rowSums(MC)
  res <- list(matriz.confusion = MC, precision.global = precision.global, error.global = error.global, 
              precision.categoria = precision.categoria)
  names(res) <- c("Matriz de Confusión", "Precisión Global", "Error Global", 
                  "Precisión por categoría")
  return(res)
}
```

# El método Redes Neuronales

Cuando usamos el paquete "neuralnet" hay que hacer una preparación de los datos extra.

### Ejemplo Scoring

```{r}
setwd("~/Desktop/Datos/")
datos<-read.csv("MuestraCredito5000V2.csv",sep = ";",header=T)

# Recodifica las variables como categóricas sin ordenar
datos$IngresoNeto <- factor(datos$IngresoNeto)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo)
```

```{r}
datos
str(datos)
```

### Distribución de las categorías

```{r}
equilibrio.variable.predecir(datos,"BuenPagador")
```

### Predicción

## {.tabset}

### Paquete neuralnet

**Se cargan las librerías**
```{r}
library(dummies)
library(neuralnet)
```

**Las variables categóricas se deben pasar a dummy y luego se tienen que escalar los datos, excepto la variable a predecir**

```{r}
datos.aux <- datos
datos.aux <- cbind(dummy.data.frame(datos.aux[, -6]), datos.aux[6])
datos.aux[, -22] <- scale(datos.aux[, -22])
datos.aux
```

**En este caso `BuenPagador` tiene valores de `No` y `Si`, por lo que hay que arreglar estos valores para que sean valores `0` y `1`**

```{r}
datos.aux$BuenPagador <- as.numeric(datos.aux$BuenPagador) - 1
datos.aux
```

**Vamos a generar al azar una tabla de testing con 15% de los datos y una tabla de aprendizaje  con 85%**

```{r}
muestra <- sample(1:nrow(datos.aux), floor(nrow(datos.aux)*0.15))
ttesting2 <- datos.aux[muestra,]
taprendizaje2 <- datos.aux[-muestra,]
```


**Se genera el modelo**
```{r}
# Obtenemos fórmula
nombres <- colnames(datos.aux)
formula <- as.formula(paste("BuenPagador ~", paste(nombres[!nombres %in% c("BuenPagador")],
                                                   collapse = " + ")))
formula

modelo <- neuralnet(formula, data = taprendizaje2, hidden = c(6, 4, 3), 
                    linear.output = FALSE, threshold = 0.2, stepmax = 1e+06)
```

**Se genera la predicción**
```{r}
# Se usa compute para predecir, la variable a predecir está en la columna 22 por eso se quita
prediccion <- neuralnet::compute(modelo, ttesting2[, -22])$net.result
prediccion <- as.numeric(round(prediccion, digits = 0))
prediccion
```

**Para obtener las clases podemos hacer lo siguiente:**
```{r}
clases <- levels(datos$BuenPagador)
prediccion <- clases[prediccion+1]
prediccion
```


**Se genera la matriz de confusión**
```{r}
real <- clases[ttesting2[,22] + 1]
MC <- table(real, as.factor(prediccion))
MC
```

**Índices de calidad de la predicción**
```{r}
indices <- indices.general(MC)
indices
```

### Paquete trainR

**Se cargan las librerías**
```{r}
library(trainR)
```

**Vamos a generar al azar una tabla de testing con 15% de los datos y una tabla de aprendizaje  con 85%**

```{r}
muestra <- sample(1:nrow(datos), floor(nrow(datos)*0.15))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
```

**Se genera el modelo**
```{r, pruebaaaaa}
modelo <- train.neuralnet(BuenPagador ~., data = taprendizaje, hidden = c(6, 4, 3), 
                          linear.output = FALSE, threshold = 0.2, stepmax = 1e+06)
```

**Se genera la predicción**
```{r}
prediccion <- predict(modelo, ttesting)
prediccion
```

**Se genera la matriz de confusión**
```{r}
MC <- confusion.matrix(ttesting, prediccion)
MC
```

**Índices de calidad de la predicción**
```{r}
indices <- general.indexes(mc = MC)
indices
```

**Podemos omitir crear la matriz de confusión**

```{r}
indices <- general.indexes(ttesting, prediccion)
indices
```

##

---

### Ejemplo Iris

```{r}
setwd("~/Desktop/Datos/")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
datos
```

```{r}
str(datos)
```


### Distribución de las categorías

```{r}
equilibrio.variable.predecir(datos, "tipo")
```

### Predicción

## {.tabset}

### Paquete neuralnet

**Se cargan las librerías**
```{r}
library(dummies)
library(neuralnet)
```

**Las variables categóricas se deben pasar a dummy y luego se tienen que escalar los datos, excepto la variable a predecir**

```{r}
datos.aux <- datos
datos.aux <- cbind(dummy.data.frame(datos.aux[, -5]), datos.aux[5])
datos.aux[, -5] <- scale(datos.aux[, -5])
```


**Hay que convertir la variable a predecir a dummy pero manteniendo los nombres de las clases**
```{r}
datos.aux <- datos.aux %>% dplyr::mutate(.valor.nuevo = TRUE, i = row_number()) %>%
                           tidyr::spread(key = "tipo", value = '.valor.nuevo', fill = FALSE) %>%
                           dplyr::select(-i)

datos.aux
```


**Vamos a generar al azar una tabla de testing de tamaño 50 y una tabla de aprendizaje de tamaño 100**
```{r}
muestra <- sample(1:nrow(datos), 50)
ttesting2 <- datos.aux[muestra,]
taprendizaje2 <- datos.aux[-muestra,]
```


**Se genera el modelo**
```{r}
# Obtenemos fórmula
nombres <- colnames(datos.aux)
clases <- unique(datos$tipo)

formula <- as.formula(paste0( paste0(paste0("`",rev(clases),"`", collapse = "+" ),"~", paste(nombres[!nombres %in% clases],
                                                   collapse = " + "))))
formula

modelo <- neuralnet(formula, data = taprendizaje2, hidden = c(6, 4, 3), 
                    linear.output = FALSE, threshold = 0.2, stepmax = 1e+06)
```

**Se genera la predicción**
```{r}
# Se usa compute para predecir, la variable a predecir está en la columna 22 por eso se quita
prediccion <- neuralnet::compute(modelo, ttesting2[, -5])$net.result
prediccion <- as.numeric(round(prediccion, digits = 0))
prediccion
```

**Para obtener las clases podemos hacer lo siguiente:**
```{r}
clases <- levels(datos$BuenPagador)
prediccion <- clases[prediccion+1]
prediccion
```


**Se genera la matriz de confusión**
```{r}
real <- clases[ttesting2[,22] + 1]
MC <- table(real, as.factor(prediccion))
MC
```

**Índices de calidad de la predicción**
```{r}
indices <- indices.general(MC)
indices
```







### Paquete trainR

**Se cargan las librerías**
```{r}
library(trainR)
```

**Se genera el modelo**
```{r}
modelo <- train.xgboost(tipo~.,data = taprendizaje, nrounds = 79,
                        print_every_n = 10, maximize = FALSE)
modelo
```

**Se genera la predicción**
```{r}
prediccion <- predict(modelo, ttesting)
prediccion
```

**Se genera la matriz de confusión**
```{r}
MC <- confusion.matrix(ttesting, prediccion)
MC
```

**Índices de calidad de la predicción**
```{r}
indices <- general.indexes(mc = MC)
indices
```

**Podemos omitir crear la matriz de confusión**

```{r}
indices <- general.indexes(ttesting, prediccion)
indices
```

##

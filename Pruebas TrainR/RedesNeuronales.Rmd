---
output:
  html_document:
    highlight: haddock
    theme: cerulean
---

![](logo.jpg)

Métodos de Predictivos (Clasificación o Aprendizaje-Supervisado)
========================================================

Dr. Oldemar Rodríguez
--------------------------

# Índices de Calidad del Modelo 

```{r st1,comment=NA,warning=FALSE}
library(tidyverse)
# Índices para matrices NxN
indices.general <- function(MC) {
  precision.global <- sum(diag(MC))/sum(MC)
  error.global <- 1 - precision.global
  precision.categoria <- diag(MC)/rowSums(MC)
  res <- list(matriz.confusion = MC, precision.global = precision.global, error.global = error.global, 
              precision.categoria = precision.categoria)
  names(res) <- c("Matriz de Confusión", "Precisión Global", "Error Global", 
                  "Precisión por categoría")
  return(res)
}

#Colores de ggplot2
define.colores <- function(n) {
  hues <- seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}  

#Calcula proporciones
dist.x.predecir <- function(data, variable, variable.predecir) {
  data. <- data %>%
    group_by_(variable, variable.predecir) %>%
    summarise(count = n()) %>%
    mutate(prop = round(count/sum(count),4))
  return(data.)
}
```

# El método Redes Neuronales

## Ejemplo Iris

### Distribución de las clases

```{r comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
barplot(prop.table(table(datos$tipo)),col=c("orange","blue","green"),main="Distribución de la variable a predecir")
```

### Predicción

```{r comment=NA,warning=FALSE}
library(nnet)
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
## Vamos a generar al azar una tabla de testing de tamaño 50 y una tabla de aprendizaje de tamaño 100.
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
# size = número de capas ocultas
# rang = pesos iniciales
# decay = grado de decrecimiento de los pesos
# maxit = número máximo de iteraciones (default=100)
# MaxNWts = Número máximo de pesos (default=1000)
modelo<-nnet(tipo~.,data=taprendizaje,size = 4, rang = 0.1,decay = 5e-4, maxit = 200,MaxNWts=500,trace=FALSE)
modelo
# Type="class" hace que el modelo prediga clases y no valores de Regresión
prediccion<-predict(modelo, ttesting[,-5],type = "class")
prediccion
## Matriz de Confusión
MC<-table(ttesting$tipo,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

### Predicción con selección de variables

```{r comment=NA,warning=FALSE}
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
library(nnet)
# size = número de capas ocultas
# rang = pesos iniciales
# decay = grado de decrecimiento de los pesos
# maxit = número máximo de iteraciones (default=100)
# MaxNWts = Número máximo de pesos (default=1000)
modelo<-nnet(tipo~p.largo+p.ancho,data=taprendizaje,size = 4, rang = 0.1,decay = 5e-4, maxit = 200,MaxNWts=500,trace=FALSE)
modelo
# Type="class" hace que el modelo prediga clases y no valores de Regresión
prediccion<-predict(modelo, ttesting[,-5],type = "class")
prediccion
## Matriz de Confusión
MC<-table(ttesting$tipo,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

## Ejemplo Scoring

### Distribución de las clases

```{r comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("MuestraCredito5000V2.csv",sep = ";",header=T)
barplot(prop.table(table(datos$BuenPagador)),col=c("orange","blue"),main="Distribución de la variable a predecir")
```

### Predicción

```{r comment=NA}
library(ada)
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("MuestraCredito5000V2.csv",sep = ";",header=T)
tam<-dim(datos)
# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
str(datos)
## Vamos a generar al azar una tabla de testing de tamaño 50 y una tabla de aprendizaje de tamaño 100.
n<-tam[1]
muestra <- sample(1:n,floor(n*0.15))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
# Genera el modelo con parámetros por defecto
# Importante size=250, con size=4 la predicción sería muy mala
modelo<-nnet(BuenPagador~.,data=taprendizaje,size = 200,MaxNWts=5000,rang = 0.1,decay = 5e-4, maxit = 200,trace=FALSE)
modelo
## Usamos una nueva tabla de testing para validar
prediccion<-predict(modelo, ttesting[,-6],type = "class")
## Matriz de Confusión
MC<-table(ttesting$BuenPagador,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```


### Selección de Variables

```{r comment=NA,fig.width=20,fig.height=10}
library(ggplot2)
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("MuestraCredito5000V2.csv",sep = ";",header=T)
# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
str(datos)

# Variable numérica
ggplot(datos, aes_string('MontoCredito', fill = 'BuenPagador')) +
geom_density( alpha = .85) +
theme_minimal() +
theme(text = element_text(size=15)) +
scale_fill_manual(values = define.colores(length(levels(datos[,'BuenPagador'])))) +
labs(title = 'Densidad de la variable MontoCredito según BuenPagador', y = '', x = '') +
theme(legend.position = 'top', legend.title = element_blank(), text = element_text(size = 15))

# Variables categóricas
colores <- define.colores(length(unique(datos[,'BuenPagador'])))
label.size <- 9.5 - length(unique(datos[,'IngresoNeto']))
label.size <- ifelse(label.size < 3, 3, label.size)
data. <- dist.x.predecir(datos, 'IngresoNeto', 'BuenPagador')
ggplot(data., aes(fct_reorder(data.[['IngresoNeto']], count, .desc = T), prop, fill = data.[['BuenPagador']])) +
geom_bar(stat = 'identity') +
geom_text(aes(label = paste0(count, ' (', scales::percent(prop), ')'), y = prop), color = 'gray90',
position = position_stack(vjust = .5), size = label.size) +
theme_minimal() +
theme(text = element_text(size=15)) +
scale_fill_manual(values = colores) +
scale_y_continuous(labels = scales::percent)+
coord_flip() +
labs(title = 'Distribución relativa de la variable IngresoNeto según la BuenPagador', x = '', y = '') +
guides(fill = guide_legend(reverse=T)) +
theme(legend.position = 'top', legend.title = element_blank())

colores <- define.colores(length(unique(datos[,'BuenPagador'])))
label.size <- 9.5 - length(unique(datos[,'CoefCreditoAvaluo']))
label.size <- ifelse(label.size < 3, 3, label.size)
data. <- dist.x.predecir(datos, 'CoefCreditoAvaluo', 'BuenPagador')
ggplot(data., aes(fct_reorder(data.[['CoefCreditoAvaluo']], count, .desc = T), prop, fill = data.[['BuenPagador']])) +
geom_bar(stat = 'identity') +
geom_text(aes(label = paste0(count, ' (', scales::percent(prop), ')'), y = prop), color = 'gray90',
position = position_stack(vjust = .5), size = label.size) +
theme_minimal() +
theme(text = element_text(size=15)) +
scale_fill_manual(values = colores) +
scale_y_continuous(labels = scales::percent)+
coord_flip() +
labs(title = 'Distribución relativa de la variable CoefCreditoAvaluo según la BuenPagador', x = '', y = '') +
guides(fill = guide_legend(reverse=T)) +
theme(legend.position = 'top', legend.title = element_blank())

colores <- define.colores(length(unique(datos[,'BuenPagador'])))
label.size <- 9.5 - length(unique(datos[,'MontoCuota']))
label.size <- ifelse(label.size < 3, 3, label.size)
data. <- dist.x.predecir(datos, 'MontoCuota', 'BuenPagador')
ggplot(data., aes(fct_reorder(data.[['MontoCuota']], count, .desc = T), prop, fill = data.[['BuenPagador']])) +
geom_bar(stat = 'identity') +
geom_text(aes(label = paste0(count, ' (', scales::percent(prop), ')'), y = prop), color = 'gray90',
position = position_stack(vjust = .5), size = label.size) +
theme_minimal() +
theme(text = element_text(size=15)) +
scale_fill_manual(values = colores) +
scale_y_continuous(labels = scales::percent)+
coord_flip() +
labs(title = 'Distribución relativa de la variable MontoCuota según la BuenPagador', x = '', y = '') +
guides(fill = guide_legend(reverse=T)) +
theme(legend.position = 'top', legend.title = element_blank())

colores <- define.colores(length(unique(datos[,'BuenPagador'])))
label.size <- 9.5 - length(unique(datos[,'GradoAcademico']))
label.size <- ifelse(label.size < 3, 3, label.size)
data. <- dist.x.predecir(datos, 'GradoAcademico', 'BuenPagador')
ggplot(data., aes(fct_reorder(data.[['GradoAcademico']], count, .desc = T), prop, fill = data.[['BuenPagador']])) +
geom_bar(stat = 'identity') +
geom_text(aes(label = paste0(count, ' (', scales::percent(prop), ')'), y = prop), color = 'gray90',
position = position_stack(vjust = .5), size = label.size) +
theme_minimal() +
theme(text = element_text(size=15)) +
scale_fill_manual(values = colores) +
scale_y_continuous(labels = scales::percent)+
coord_flip() +
labs(title = 'Distribución relativa de la variable GradoAcademico según la BuenPagador', x = '', y = '') +
guides(fill = guide_legend(reverse=T)) +
theme(legend.position = 'top', legend.title = element_blank())
```

### Predicción con selección de variables

```{r comment=NA}
library(ada)
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("MuestraCredito5000V2.csv",sep = ";",header=T)
tam<-dim(datos)
# Recodifica las variables como categóricas ordinales
datos$IngresoNeto <- factor(datos$IngresoNeto,ordered = TRUE)
datos$CoefCreditoAvaluo <- factor(datos$CoefCreditoAvaluo,ordered = TRUE)
str(datos)
## Vamos a generar al azar una tabla de testing de tamaño 50 y una tabla de aprendizaje de tamaño 100.
n<-tam[1]
muestra <- sample(1:n,floor(n*0.15))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
# Genera el modelo con parámetros por defecto
# Importante size=250, con size=4 la predicción sería muy mala
modelo<-nnet(BuenPagador~CoefCreditoAvaluo+MontoCredito+IngresoNeto,data=taprendizaje,size = 200,MaxNWts=5000,rang = 0.1,decay = 5e-4, maxit = 200,trace=FALSE)
modelo
## Usamos una nueva tabla de testing para validar
prediccion<-predict(modelo, ttesting[,-6],type = "class")
## Matriz de Confusión
MC<-table(ttesting$BuenPagador,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

# Guardar en disco el modelo

```{r guarda1,comment=NA}
library(nnet)
# Leyendo Datos
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
muestra <- sample(1:150,50)
taprendizaje <- datos[-muestra,]
modelo<-nnet(tipo~.,data=taprendizaje,size = 4, rang = 0.1,decay = 5e-4, maxit = 200,trace=FALSE)
#Guarda el modelo
save(modelo, file = "modelo_redes_iris.rda")
```


## Un mes después, por ejemplo, lee el modelo y hace predicciones


```{r guarda2,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
datos<-read.csv("iris.csv",sep = ";",dec='.',header=T)
muestra <- sample(1:150,50)
ttesting <- datos[muestra,]
# Automáticamente queda en la variable en la que fue guardada, o sea modelo
load("modelo_redes_iris.rda")  
# Type="class" hace que el modelo prediga clases y no valores de Regresión
prediccion<-predict(modelo, ttesting[,-5],type = "class")
## Matriz de Confusión
MC<-table(ttesting$tipo,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```

# Ejemplo con los datos de Scoring y Bosques Aleatorios


## Guardar en disco el modelo


```{r guarda3,comment=NA}
# Leyendo Datos
library(randomForest)
setwd("~/Google Drive/MDCurso/Datos")
taprendizaje<-read.csv("MuestraAprendizajeCredito2500.csv",sep = ";",header=T)
modelo<-randomForest(BuenPagador~.,data=taprendizaje,importance=TRUE)
#Guarda el modelo
save(modelo, file = "modelo_bosques_scoring.rda")
```


# Un mes después, por ejemplo, lee el modelo y hacen predicciones

```{r guarda4,comment=NA}
setwd("~/Google Drive/MDCurso/Datos")
ttesting<-read.csv("MuestraTestCredito2500.csv",sep = ";",header=T)
# Lee el modelo del disco duro
load("modelo_bosques_scoring.rda")  
prediccion<-predict(modelo, ttesting[,-6])
## Matriz de Confusión
MC<-table(ttesting$BuenPagador,prediccion)
# Índices de Calidad de la predicción
indices.general(MC)
```
